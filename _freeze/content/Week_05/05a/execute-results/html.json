{
  "hash": "7005bfb721fe39a34df9fb0038c39259",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Wrangling\"\ntype: docs\noutput:\n  blogdown::html_page:\n    toc: true\n---\n\n\n\n\n\n## Required Reading\n\n- This page.\n\n### Guiding Questions\n\n- How can we reshape data into a useable `tidy` form?\n- What is a _join_ and why is it a common data wrangling maneuver?\n- What is a _primary key_ and why is it important to think about our data in this way?\n- How do we deal with messy date variables?\n\n\n# Introduction to data wrangling\n\nMany of the datasets used in this class have been made available to you as `R` objects, specifically as data frames. The US murders data, the reported heights data, and the Gapminder data were all data frames. Furthermore, much of the data is available in what is referred to as `tidy` form. The tidyverse packages and functions assume that the data is `tidy` and this assumption is a big part of the reason these packages work so well together.\n\nHowever, very rarely in a data science project is data easily available as part of a package. People did quite a bit of work \"behind the scenes\" to get the original raw data into the _tidy_ tables. Much more typical is for the data to be in a file, a database, or extracted from a document, including web pages, tweets, or PDFs. In these cases, the first step is to import the data into `R` and, when using the __tidyverse__, tidy up the data. This initial step in the data analysis process usually involves several, often complicated, steps to convert data from its raw form to the _tidy_ form that greatly facilitates the rest of the analysis. We refer to this process as `data wrangling`.\n\nHere we cover several common steps of the data wrangling process including tidying data, string processing, html parsing, working with dates and times, and text mining. Rarely are __all__ these wrangling steps necessary in a single analysis, but data scientists will likely face them all at some point.\n\n# Reshaping data\n\nAs we have seen through the class, having data in _tidy_ format is what makes the tidyverse flow. After the first step in the data analysis process, importing data, a common next step is to reshape the data into a form that facilitates the rest of the analysis. The __tidyr__ package includes several functions that are useful for tidying data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dslabs)\nlibrary(here)\nlibrary(knitr)\npath <- system.file(\"extdata\", package=\"dslabs\")\nfilename <- file.path(path, \"fertility-two-countries-example.csv\")\nwide_data <- read_csv(filename)\nhead(wide_data[,1:8])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 8\n  country     `1960` `1961` `1962` `1963` `1964` `1965` `1966`\n  <chr>        <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Germany       2.41   2.44   2.47   2.49   2.49   2.48   2.44\n2 South Korea   6.16   5.99   5.79   5.57   5.36   5.16   4.99\n```\n\n\n:::\n:::\n\n\n\n\n\n## `gather`\n\nOne of the most used functions in the __tidyr__ package is `gather`, which is useful for converting wide data into tidy data.\n\nLooking at the data above, the fundamental problem is that **the column name contains data**. This is a problem indeed! And a common one.\n\n### The `gather` arguments\n\nHere we want to reshape the `wide_data` dataset so that each row represents a country's yearly fertility observation, which implies we need three columns to store the year, country, and the observed value. In its current form, data from different years are in different columns with the year values stored in the column names. \n\nAs with most tidyverse functions, the `gather` function's first argument is the data frame that will be converted. Easy enough.\n\nThe second and third arguments will tell `gather` the column names we want to assign to the columns containing the **current column names** and **the observed data**, respectively. In this case a good choice for these two arguments would be something like `year` and `fertility`. These are not currenly column names in the data -- they are names we want to use to *hold* data currently located in the \"wide\" columns. We know this is fertility data only because we deciphered it from the file name.\n\nThe fourth argument specifies the columns **containing observed values**; these are the columns that will be _gathered_. The default (if we leave out the 4th argument) is to gather **all** columns so, in most cases, we have to specify the columns. In our example we want columns `1960`, `1961` up to `2015`. Since these are non-standard column names, we have to backtick them so R doesn't think they're to be treated as integers:\n\nThe code to gather the fertility data therefore looks like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_tidy_data <- gather(wide_data, year, fertility, `1960`:`2015`)\n```\n:::\n\n\n\n\nWe can also use the pipe like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_tidy_data <- wide_data %>% gather(year, fertility, `1960`:`2015`)\n```\n:::\n\n\n\n\nWe can see that the data have been converted to tidy format with columns `year` and `fertility`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(new_tidy_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  country     year  fertility\n  <chr>       <chr>     <dbl>\n1 Germany     1960       2.41\n2 South Korea 1960       6.16\n3 Germany     1961       2.44\n4 South Korea 1961       5.99\n5 Germany     1962       2.47\n6 South Korea 1962       5.79\n```\n\n\n:::\n:::\n\n\n\n\nWe have the first column, which consists of \"everything in the data that wasn't gathered\", the next two columns are named based on the arguments we gave. The second column, named by our argument above, contains the column names of the wide data. The third column, also named by our argument above, contains the value that was in each corresponding colum x country pair. What you leave *out* of the 4th argument is important!\n\nNote that each year resulted in two rows since we have two countries and this column was not gathered.\nA somewhat quicker way to write this code is to specify which column will **not** be gathered, rather than all the columns that will be gathered:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_tidy_data <- wide_data %>%\n  gather(year, fertility, -country)\n\nhead(new_tidy_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  country     year  fertility\n  <chr>       <chr>     <dbl>\n1 Germany     1960       2.41\n2 South Korea 1960       6.16\n3 Germany     1961       2.44\n4 South Korea 1961       5.99\n5 Germany     1962       2.47\n6 South Korea 1962       5.79\n```\n\n\n:::\n:::\n\n\n\n\nThe `new_tidy_data` object looks like the original `tidy_data` we defined this way\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"gapminder\")\ntidy_data <- gapminder %>%\n  dplyr::filter(country %in% c(\"South Korea\", \"Germany\") & !is.na(fertility)) %>%\n  dplyr::select(country, year, fertility)\n```\n:::\n\n\n\n\nwith just one minor difference. Can you spot it? Look at the data type of the year column:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(tidy_data$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"integer\"\n```\n\n\n:::\n\n```{.r .cell-code}\nclass(new_tidy_data$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"character\"\n```\n\n\n:::\n:::\n\n\n\n\nThe `gather` function assumes that column names are characters. So we need a bit more wrangling before we are ready to make a plot. We need to convert the year column to be numbers. The `gather` function includes the `convert` argument for this purpose:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_tidy_data <- wide_data %>%\n  gather(year, fertility, -country, convert = TRUE)\nclass(new_tidy_data$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"integer\"\n```\n\n\n:::\n:::\n\n\n\n\nNote that we could have also used the `mutate` and `as.numeric`.\n\nNow that the data is tidy, we can use this relatively simple ggplot code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_tidy_data %>% ggplot(aes(year, fertility, color = country)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](05a_files/figure-html/fertility-year-check-1.png){width=672}\n:::\n:::\n\n\n\n\n## `spread`\n\nAs we will see in later examples, it is sometimes useful for data wrangling purposes to convert tidy data into wide data. We often use this as an intermediate step in tidying up data. The `spread` function is basically the inverse of `gather`. The first argument is for the data, but since we are using the pipe, we don't show it. The second argument tells `spread` which variable will be used as the column names. The third argument specifies which variable to use to fill out the cells:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_wide_data <- new_tidy_data %>% spread(year, fertility)\ndplyr::select(new_wide_data, country, `1960`:`1967`)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 9\n  country     `1960` `1961` `1962` `1963` `1964` `1965` `1966` `1967`\n  <chr>        <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Germany       2.41   2.44   2.47   2.49   2.49   2.48   2.44   2.37\n2 South Korea   6.16   5.99   5.79   5.57   5.36   5.16   4.99   4.85\n```\n\n\n:::\n:::\n\n\n\n\nThe following diagram can help remind you how these two functions work:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/gather-spread.png){width=601}\n:::\n:::\n\n\n\n\n\n(Image courtesy of RStudio^[https://github.com/rstudio/cheatsheets]. CC-BY-4.0 license^[https://github.com/rstudio/cheatsheets/blob/master/LICENSE]. Cropped from original.)\n<!-- (Source: RStudio. The image is a section of this [cheat sheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf).)-->\n\n## `separate` {#separate}\n\nThe data wrangling shown above was simple compared to what is usually required. In our example spreadsheet files, we include an illustration that is slightly more complicated. It contains two variables: life expectancy and fertility. However, the way it is stored is not tidy and, as we will explain, not optimal.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath <- system.file(\"extdata\", package = \"dslabs\")\n\nfilename <- \"life-expectancy-and-fertility-two-countries-example.csv\"\nfilename <-  file.path(path, filename)\n\nraw_dat <- read_csv(filename)\ndplyr::select(raw_dat, 1:5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  country     `1960_fertility` `1960_life_expectancy` `1961_fertility`\n  <chr>                  <dbl>                  <dbl>            <dbl>\n1 Germany                 2.41                   69.3             2.44\n2 South Korea             6.16                   53.0             5.99\n# ℹ 1 more variable: `1961_life_expectancy` <dbl>\n```\n\n\n:::\n:::\n\n\n\n\nFirst, note that the data is in wide format. Second, notice that this table includes values for two variables, fertility and life expectancy, with the column name encoding which column represents which variable. Encoding information in the column names is not recommended but, unfortunately, it is quite common. We will put our wrangling skills to work to extract this information and store it in a tidy fashion.\n\nWe can start the data wrangling with the `gather` function, but we should no longer use the column name `year` for the new column since it also contains the variable type. We will call it `key`, the default, for now:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- raw_dat %>% gather(key, value, -country)\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  country     key                  value\n  <chr>       <chr>                <dbl>\n1 Germany     1960_fertility        2.41\n2 South Korea 1960_fertility        6.16\n3 Germany     1960_life_expectancy 69.3 \n4 South Korea 1960_life_expectancy 53.0 \n5 Germany     1961_fertility        2.44\n6 South Korea 1961_fertility        5.99\n```\n\n\n:::\n:::\n\n\n\n\nThe result is not exactly what we refer to as tidy since each observation (year-country combination) is associated with two, not one, rows. We want to have the values from the two variables, fertility and life expectancy, in two separate columns. The first challenge to achieve this is to separate the `key` column into the year and the variable type. Notice that the entries in this column separate the year from the variable name with an underscore:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$key[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"1960_fertility\"       \"1960_fertility\"       \"1960_life_expectancy\"\n[4] \"1960_life_expectancy\" \"1961_fertility\"      \n```\n\n\n:::\n:::\n\n\n\n\nEncoding multiple variables in a column name is such a common problem that the __tidyverse__ package includes a function to separate these columns into two or more. Apart from the data, the `separate` function takes three arguments: the name of the column to be separated, the names to be used for the new columns, and the character that separates the variables. So, a first attempt at this is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>% separate(col = key, into = c(\"year\", \"variable_name\"), sep = \"_\")\n```\n:::\n\n\n\n\n\n\nThe function does separate the values, but we run into a new problem. We receive the warning `Additional pieces discarded in 112 rows [3, 4, 7,...]`. (Earlier versions may give the error `Too many values at 112 locations:`) and that the `life_expectancy` variable is truncated to `life`. This is because the `_` is used to separate `life` and `expectancy`, not just year and variable name! We could add a third column to catch this and let the `separate` function know which column to _fill in_ with missing values, `NA`, when there is no third value. Here we tell it to fill the column on the right:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>% separate(key, into = c(\"year\", \"first_variable_name\", \"second_variable_name\"), fill = \"right\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 224 × 5\n   country     year  first_variable_name second_variable_name value\n   <chr>       <chr> <chr>               <chr>                <dbl>\n 1 Germany     1960  fertility           <NA>                  2.41\n 2 South Korea 1960  fertility           <NA>                  6.16\n 3 Germany     1960  life                expectancy           69.3 \n 4 South Korea 1960  life                expectancy           53.0 \n 5 Germany     1961  fertility           <NA>                  2.44\n 6 South Korea 1961  fertility           <NA>                  5.99\n 7 Germany     1961  life                expectancy           69.8 \n 8 South Korea 1961  life                expectancy           53.8 \n 9 Germany     1962  fertility           <NA>                  2.47\n10 South Korea 1962  fertility           <NA>                  5.79\n# ℹ 214 more rows\n```\n\n\n:::\n:::\n\n\n\n\nHowever, if we read the `separate` help file, we find that a better approach is to merge the last two variables when there is an extra separation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>% separate(key, into = c(\"year\", \"variable_name\"), extra = \"merge\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 224 × 4\n   country     year  variable_name   value\n   <chr>       <chr> <chr>           <dbl>\n 1 Germany     1960  fertility        2.41\n 2 South Korea 1960  fertility        6.16\n 3 Germany     1960  life_expectancy 69.3 \n 4 South Korea 1960  life_expectancy 53.0 \n 5 Germany     1961  fertility        2.44\n 6 South Korea 1961  fertility        5.99\n 7 Germany     1961  life_expectancy 69.8 \n 8 South Korea 1961  life_expectancy 53.8 \n 9 Germany     1962  fertility        2.47\n10 South Korea 1962  fertility        5.79\n# ℹ 214 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThis achieves the separation we wanted. However, we are not done yet. We need to create a column for each variable. As we learned, the `spread` function can do this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>%\n  separate(key, c(\"year\", \"variable_name\"), extra = \"merge\") %>%\n  spread(variable_name, value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 112 × 4\n   country year  fertility life_expectancy\n   <chr>   <chr>     <dbl>           <dbl>\n 1 Germany 1960       2.41            69.3\n 2 Germany 1961       2.44            69.8\n 3 Germany 1962       2.47            70.0\n 4 Germany 1963       2.49            70.1\n 5 Germany 1964       2.49            70.7\n 6 Germany 1965       2.48            70.6\n 7 Germany 1966       2.44            70.8\n 8 Germany 1967       2.37            71.0\n 9 Germany 1968       2.28            70.6\n10 Germany 1969       2.17            70.5\n# ℹ 102 more rows\n```\n\n\n:::\n:::\n\n\n\n\nThe data is now in tidy format with one row for each observation with three variables: year, fertility, and life expectancy.\n\n## `unite`\n\nIt is sometimes useful to do the inverse of `separate`, unite two columns into one. To demonstrate how to use `unite`, we show code that, although *not* the optimal approach, serves as an illustration. Suppose that we did not know about `extra` and used this command to separate:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>%\n  separate(key, c(\"year\", \"first_variable_name\", \"second_variable_name\"), fill = \"right\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 224 × 5\n   country     year  first_variable_name second_variable_name value\n   <chr>       <chr> <chr>               <chr>                <dbl>\n 1 Germany     1960  fertility           <NA>                  2.41\n 2 South Korea 1960  fertility           <NA>                  6.16\n 3 Germany     1960  life                expectancy           69.3 \n 4 South Korea 1960  life                expectancy           53.0 \n 5 Germany     1961  fertility           <NA>                  2.44\n 6 South Korea 1961  fertility           <NA>                  5.99\n 7 Germany     1961  life                expectancy           69.8 \n 8 South Korea 1961  life                expectancy           53.8 \n 9 Germany     1962  fertility           <NA>                  2.47\n10 South Korea 1962  fertility           <NA>                  5.79\n# ℹ 214 more rows\n```\n\n\n:::\n:::\n\n\n\n\nWe can achieve the same final result by uniting the second and third columns, then spreading the columns and renaming `fertility_NA` to `fertility`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>%\n  separate(key, c(\"year\", \"first_variable_name\", \"second_variable_name\"), fill = \"right\") %>%\n  unite(variable_name, first_variable_name, second_variable_name) %>%\n  spread(variable_name, value) %>%\n  rename(fertility = fertility_NA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 112 × 4\n   country year  fertility life_expectancy\n   <chr>   <chr>     <dbl>           <dbl>\n 1 Germany 1960       2.41            69.3\n 2 Germany 1961       2.44            69.8\n 3 Germany 1962       2.47            70.0\n 4 Germany 1963       2.49            70.1\n 5 Germany 1964       2.49            70.7\n 6 Germany 1965       2.48            70.6\n 7 Germany 1966       2.44            70.8\n 8 Germany 1967       2.37            71.0\n 9 Germany 1968       2.28            70.6\n10 Germany 1969       2.17            70.5\n# ℹ 102 more rows\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-note}\n\n## TRY IT\n\n1. Run the following command to define the `co2_wide` object using the `co2` data built in to R (see `?co2`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nco2_wide <- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) %>%\n  setNames(1:12) %>%\n  mutate(year = as.character(1959:1997))\n```\n:::\n\n\n\n\nUse the gather function to wrangle this into a tidy dataset. Call the column with the CO2 measurements `co2` and call the month column `month`. Call the resulting object `co2_tidy`.\n\n\n2. Plot CO2 versus month with a different curve for each year using this code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nco2_tidy %>% ggplot(aes(month, co2, color = year)) + geom_line()\n```\n:::\n\n\n\n\nIf the expected plot is not made, it is probably because `co2_tidy$month` is not numeric:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(co2_tidy$month)\n```\n:::\n\n\n\n\n\nRewrite the call to gather using an argument that assures the month column will be numeric. Then make the plot.\n\n\n3. What do we learn from this plot?\n\na. CO2 measures increase monotonically from 1959 to 1997.\nb. CO2 measures are higher in the summer and the yearly average increased from 1959 to 1997.\nc. CO2 measures appear constant and random variability explains the differences.\nc. CO2 measures do not have a seasonal trend.\n\n\n4. Now load the `admissions` data set, which contains admission information for men and women across six majors and keep only the admitted percentage column:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(admissions)\ndat <- admissions %>% dplyr::select(-applicants)\n```\n:::\n\n\n\n\nIf we think of an observation as a major, and that each observation has two variables (men admitted percentage and women admitted percentage) then this is not tidy. Use the `spread` function to wrangle into tidy shape: one row for each major.\n\n\n5. Now we will try a more advanced wrangling challenge. We want to wrangle the admissions data so that for each major we have 4 observations: `admitted_men`, `admitted_women`, `applicants_men` and `applicants_women`.  The _trick_ we perform here is actually quite common: first gather to generate an intermediate data frame and then spread to obtain the tidy data we want. We will go step by step in this and the next two exercises.\n\nUse the gather function to create a `tmp` data.frame with a column containing the type of observation `admitted` or `applicants`. Call the new columns `key` and value.\n\n\n6. Now you have an object `tmp` with columns `major`,  `gender`, `key` and  `value`. Note that if you combine the key and gender, we get the column names we want: `admitted_men`, `admitted_women`, `applicants_men` and `applicants_women`. Use the function `unite` to create a new column called `column_name`.\n\n7. Now use the `spread` function to generate the tidy data with four variables for each major.\n\n8. Now use the pipe to write a line of code that turns `admissions` to the table  produced in the previous exercise.\n\n:::\n\n# Joining tables\n\nThe information we need for a given analysis may not be just in one table. For example, when forecasting elections we used the function `left_join` to combine the information from two tables. We also saw this in action using the `WDI` function (technically, the `WDI` API) in Project 2. Here we use a simpler example to illustrate the general challenge of combining tables.\n\nSuppose we want to explore the relationship between population size for US states and electoral votes. We have the population size in this table:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(murders)\nhead(murders)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state abb region population total\n1    Alabama  AL  South    4779736   135\n2     Alaska  AK   West     710231    19\n3    Arizona  AZ   West    6392017   232\n4   Arkansas  AR  South    2915918    93\n5 California  CA   West   37253956  1257\n6   Colorado  CO   West    5029196    65\n```\n\n\n:::\n:::\n\n\n\n\nand electoral votes in this one:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(polls_us_election_2016)\nhead(results_us_election_2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         state electoral_votes clinton trump others\n1   California              55    61.7  31.6    6.7\n2        Texas              38    43.2  52.2    4.5\n3      Florida              29    47.8  49.0    3.2\n4     New York              29    59.0  36.5    4.5\n5     Illinois              20    55.8  38.8    5.4\n6 Pennsylvania              20    47.9  48.6    3.6\n```\n\n\n:::\n:::\n\n\n\n\nJust concatenating these two tables together will not work since the order of the states is not the same.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidentical(results_us_election_2016$state, murders$state)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\n\nThe _join_ functions, described below, are designed to handle this challenge.\n\n## Joins {#joins}\n\nThe _join_ functions in the __dplyr__ package (part of the tidyverse) make sure that the tables are combined so that matching rows are together. If you know SQL, you will see that the approach and syntax is very similar. The general idea is that one needs to identify one or more columns that will serve to match the two tables. Then a new table with the combined information is returned. Notice what happens if we join the two tables above by state using `left_join` (we will remove the `others` column and rename `electoral_votes` so that the tables fit on the page):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- left_join(murders, results_us_election_2016, by = \"state\") %>%\n  dplyr::select(-others) %>% \n  rename(ev = electoral_votes)\nhead(tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state abb region population total ev clinton trump\n1    Alabama  AL  South    4779736   135  9    34.4  62.1\n2     Alaska  AK   West     710231    19  3    36.6  51.3\n3    Arizona  AZ   West    6392017   232 11    45.1  48.7\n4   Arkansas  AR  South    2915918    93  6    33.7  60.6\n5 California  CA   West   37253956  1257 55    61.7  31.6\n6   Colorado  CO   West    5029196    65  9    48.2  43.3\n```\n\n\n:::\n:::\n\n\n\n\nThe data has been successfully joined and we can now, for example, make a plot to explore the relationship:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggrepel)\ntab %>% ggplot(aes(population/10^6, ev, label = abb)) +\n  geom_point() +\n  geom_text_repel() +\n  scale_x_continuous(trans = \"log2\") +\n  scale_y_continuous(trans = \"log2\") +\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](05a_files/figure-html/ev-vs-population-1.png){width=672}\n:::\n:::\n\n\n\n\nWe see the relationship is close to linear with about 2 electoral votes for every million persons, but with very small states getting higher ratios.\n\n\nIn practice, it is not always the case that each row in one table has a matching row in the other. For this reason, we have several versions of join. To illustrate this challenge, we will take subsets of the tables above. We create the tables `tab1` and `tab2` so that they have some states in common but not all:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 <- slice(murders, 1:6) %>% dplyr::select(state, population)\ntab_1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4   Arkansas    2915918\n5 California   37253956\n6   Colorado    5029196\n```\n\n\n:::\n\n```{.r .cell-code}\ntab_2 <- results_us_election_2016 %>%\n  dplyr::filter(state%in%c(\"Alabama\", \"Alaska\", \"Arizona\",\n                    \"California\", \"Connecticut\", \"Delaware\")) %>%\n  dplyr::select(state, electoral_votes) %>% rename(ev = electoral_votes)\ntab_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        state ev\n1  California 55\n2     Arizona 11\n3     Alabama  9\n4 Connecticut  7\n5      Alaska  3\n6    Delaware  3\n```\n\n\n:::\n:::\n\n\n\n\n\nWe will use these two tables as examples in the next sections.\n\n### Left join\n\nSuppose we want a table like `tab_1`, but adding electoral votes to whatever states we have available. For this, we use `left_join` with `tab_1` as the first argument. We specify which column to use to match with the `by` argument.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleft_join(tab_1, tab_2, by = \"state\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state population ev\n1    Alabama    4779736  9\n2     Alaska     710231  3\n3    Arizona    6392017 11\n4   Arkansas    2915918 NA\n5 California   37253956 55\n6   Colorado    5029196 NA\n```\n\n\n:::\n:::\n\n\n\n\nNote that `NA`s are added to the two states not appearing in `tab_2`. Also, notice that this function, as well as all the other joins, can receive the first arguments through the pipe:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 %>% left_join(tab_2, by = \"state\")\n```\n:::\n\n\n\n\n\n### Right join\n\nIf instead of a table with the same rows as first table, we want one with the same rows as second table, we can use `right_join`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 %>% right_join(tab_2, by = \"state\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        state population ev\n1     Alabama    4779736  9\n2      Alaska     710231  3\n3     Arizona    6392017 11\n4  California   37253956 55\n5 Connecticut         NA  7\n6    Delaware         NA  3\n```\n\n\n:::\n:::\n\n\n\n\nNow the NAs are in the column coming from `tab_1`.\n\n### Inner join\n\nIf we want to keep only the rows that have information in both tables, we use `inner_join`. You can think of this as an intersection:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninner_join(tab_1, tab_2, by = \"state\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state population ev\n1    Alabama    4779736  9\n2     Alaska     710231  3\n3    Arizona    6392017 11\n4 California   37253956 55\n```\n\n\n:::\n:::\n\n\n\n\n### Full join\n\nIf we want to keep all the rows and fill the missing parts with NAs, we can use `full_join`. You can think of this as a union:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_join(tab_1, tab_2, by = \"state\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        state population ev\n1     Alabama    4779736  9\n2      Alaska     710231  3\n3     Arizona    6392017 11\n4    Arkansas    2915918 NA\n5  California   37253956 55\n6    Colorado    5029196 NA\n7 Connecticut         NA  7\n8    Delaware         NA  3\n```\n\n\n:::\n:::\n\n\n\n\n### Semi join\n\nThe `semi_join` function lets us keep the part of first table for which we have information in the second. It does not add the columns of the second. It isn't often used:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsemi_join(tab_1, tab_2, by = \"state\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4 California   37253956\n```\n\n\n:::\n:::\n\n\n\nThis gives the same result as:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 %>% \n  filter(state %in% tab_2$state) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4 California   37253956\n```\n\n\n:::\n:::\n\n\n\n\n### Anti join\n\nThe function `anti_join` is the opposite of `semi_join`. It keeps the elements of the first table for which there is no information in the second:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanti_join(tab_1, tab_2, by = \"state\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     state population\n1 Arkansas    2915918\n2 Colorado    5029196\n```\n\n\n:::\n:::\n\n\n\n\nThe following diagram summarizes the above joins:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/joins.png){width=388}\n:::\n:::\n\n\n\n(Image courtesy of RStudio^[https://github.com/rstudio/cheatsheets]. CC-BY-4.0 license^[https://github.com/rstudio/cheatsheets/blob/master/LICENSE]. Cropped from original.)\n\n## Binding\n\nAlthough we have yet to use it in this book, another common way in which datasets are combined is by _binding_ them. Unlike the join function, the binding functions do not try to match by a variable, but instead simply combine datasets. If the datasets don't match by the appropriate dimensions, one obtains an error.\n\n### Binding columns\n\nThe __dplyr__ function _bind_cols_ binds two objects by making them columns in a tibble. For example, we quickly want to make a data frame consisting of numbers we can use.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_cols(a = 1:3, b = 4:6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n      a     b\n  <int> <int>\n1     1     4\n2     2     5\n3     3     6\n```\n\n\n:::\n:::\n\n\n\n\nThis function requires that we assign names to the columns. Here we chose `a` and `b`.\n\nNote that there is an R-base function `cbind` with the exact same functionality. An important difference is that `cbind` can create different types of objects, while `bind_cols` always produces a data frame.\n\n`bind_cols` can also bind two different data frames. For example, here we break up the `tab` data frame and then bind them back together:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 <- tab[, 1:3]\ntab_2 <- tab[, 4:6]\ntab_3 <- tab[, 7:8]\nnew_tab <- bind_cols(tab_1, tab_2, tab_3)\nhead(new_tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state abb region population total ev clinton trump\n1    Alabama  AL  South    4779736   135  9    34.4  62.1\n2     Alaska  AK   West     710231    19  3    36.6  51.3\n3    Arizona  AZ   West    6392017   232 11    45.1  48.7\n4   Arkansas  AR  South    2915918    93  6    33.7  60.6\n5 California  CA   West   37253956  1257 55    61.7  31.6\n6   Colorado  CO   West    5029196    65  9    48.2  43.3\n```\n\n\n:::\n:::\n\n\n\n\n\n### Binding by rows\n\nThe `bind_rows` function is similar to `bind_cols`, but binds rows instead of columns:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 <- tab[1:2,]\ntab_2 <- tab[3:4,]\nbind_rows(tab_1, tab_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     state abb region population total ev clinton trump\n1  Alabama  AL  South    4779736   135  9    34.4  62.1\n2   Alaska  AK   West     710231    19  3    36.6  51.3\n3  Arizona  AZ   West    6392017   232 11    45.1  48.7\n4 Arkansas  AR  South    2915918    93  6    33.7  60.6\n```\n\n\n:::\n:::\n\n\n\n\nThis is based on an R-base function `rbind`.\n\n## Set operators\n\nAnother set of commands useful for combining datasets are the set operators. When applied to vectors, these behave as their names suggest. Examples are `intersect`, `union`, `setdiff`, and `setequal`. However, if the __tidyverse__, or  more specifically __dplyr__, is loaded, these functions can be used on data frames as opposed to just on vectors.\n\n### Intersect\n\nYou can take intersections of vectors of any type, such as numeric:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintersect(1:10, 6:15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  6  7  8  9 10\n```\n\n\n:::\n:::\n\n\n\nor characters:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintersect(c(\"a\",\"b\",\"c\"), c(\"b\",\"c\",\"d\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"b\" \"c\"\n```\n\n\n:::\n:::\n\n\n\n\nThe __dplyr__ package includes an `intersect` function that can be applied to tables with the same column names. This function returns the rows in common between two tables. To make sure we use the __dplyr__ version of `intersect` rather than the base package version, we can use `dplyr::intersect` like this:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 <- tab[1:5,]\ntab_2 <- tab[3:7,]\ndplyr::intersect(tab_1, tab_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state abb region population total ev clinton trump\n1    Arizona  AZ   West    6392017   232 11    45.1  48.7\n2   Arkansas  AR  South    2915918    93  6    33.7  60.6\n3 California  CA   West   37253956  1257 55    61.7  31.6\n```\n\n\n:::\n:::\n\n\n\n\n\n### Union\n\nSimilarly _union_ takes the union of vectors. For example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunion(1:10, 6:15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n```\n\n\n:::\n\n```{.r .cell-code}\nunion(c(\"a\",\"b\",\"c\"), c(\"b\",\"c\",\"d\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"a\" \"b\" \"c\" \"d\"\n```\n\n\n:::\n:::\n\n\n\n\nThe __dplyr__ package includes a version of `union` that combines all the rows of two tables with the same column names.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 <- tab[1:5,]\ntab_2 <- tab[3:7,]\ndplyr::union(tab_1, tab_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        state abb    region population total ev clinton trump\n1     Alabama  AL     South    4779736   135  9    34.4  62.1\n2      Alaska  AK      West     710231    19  3    36.6  51.3\n3     Arizona  AZ      West    6392017   232 11    45.1  48.7\n4    Arkansas  AR     South    2915918    93  6    33.7  60.6\n5  California  CA      West   37253956  1257 55    61.7  31.6\n6    Colorado  CO      West    5029196    65  9    48.2  43.3\n7 Connecticut  CT Northeast    3574097    97  7    54.6  40.9\n```\n\n\n:::\n:::\n\n\n\nNote that we get 7 unique rows from this. We do not get duplicated rows from the overlap in `1:5` and `3:7`. If we were to `bind_rows` on the two subsets, we would get duplicates.\n\n### `setdiff`\n\nThe set difference between a first and second argument can be obtained with `setdiff`. Unlike `intersect` and `union`, this function is not symmetric:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetdiff(1:10, 6:15)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1 2 3 4 5\n```\n\n\n:::\n\n```{.r .cell-code}\nsetdiff(6:15, 1:10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 11 12 13 14 15\n```\n\n\n:::\n:::\n\n\n\n\nAs with the functions shown above, __dplyr__ has a version for data frames:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_1 <- tab[1:5,]\ntab_2 <- tab[3:7,]\ndplyr::setdiff(tab_1, tab_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    state abb region population total ev clinton trump\n1 Alabama  AL  South    4779736   135  9    34.4  62.1\n2  Alaska  AK   West     710231    19  3    36.6  51.3\n```\n\n\n:::\n:::\n\n\n\n\n### `setequal`\n\nFinally, the function `setequal` tells us if two sets are the same, regardless of order. So notice that:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetequal(1:5, 1:6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\n\nbut:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetequal(1:5, 5:1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\nWhen applied to data frames that are not equal, regardless of order, the __dplyr__ version provides a useful message letting us know how the sets are different:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::setequal(tab_1, tab_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\n\n\n:::fyi\n\n__TRY IT__\n\n1. Install and load the __Lahman__ library. This database includes data related to baseball teams. It includes summary statistics about how the players performed on offense and defense for several years. It also includes personal information about the players.\n\nThe `Batting` data frame contains the offensive statistics for all players for many years. You can see, for example, the top 10 hitters by running this code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Lahman)\n\ntop <- Batting %>%\n  dplyr::filter(yearID == 2016) %>%\n  arrange(desc(HR)) %>%\n  slice(1:10)\n\ntop %>% as_tibble()\n```\n:::\n\n\n\n\nBut who are these players? We see an ID, but not the names. The player names are in this table\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMaster %>% as_tibble()\n```\n:::\n\n\n\n\nWe can see column names `nameFirst` and `nameLast`. Use the `left_join` function to create a table of the top home run hitters. The table should have `playerID`, first name, last name, and number of home runs (HR).  Rewrite the object `top` with this new table.\n\n\n\n2. Now use the `Salaries` data frame to add each player's salary to the table you created in exercise 1. Note that salaries are different every year so make sure to filter for the year 2016, then use `right_join`. This time show first name, last name, team, HR, and salary.\n\n\n\n3. In a previous exercise, we created a tidy version of the `co2` dataset:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nco2_wide <- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) %>%\n  setNames(1:12) %>%\n  mutate(year = 1959:1997) %>%\n  gather(month, co2, -year, convert = TRUE)\n```\n:::\n\n\n\n\nWe want to see if the monthly trend is changing so we are going to remove the year effects and then plot the results. We will first compute the year averages. Use the `group_by` and `summarize` to compute the average co2 for each year. Save in an object called `yearly_avg`.\n\n\n4. Now use the `left_join` function to add the yearly average to the `co2_wide` dataset. Then compute the residuals: observed co2 measure - yearly average.\n\n\n5. Make a plot of the seasonal trends by year but only after removing the year effect.\n\n:::\n\n\n## A note about merging and duplicated rows\n\nWhen we merge data, we have to be very careful about duplicated rows. Specifically, we have to be certain that the fields we use to join on are unique **or** that we know they aren't unique and intend to duplicate rows.\n\nWhen we have tidy data, we have one row per observation. When we join data that has more than one row per observation, the new dataset will no longer be tidy. Here, the `notTidyData` is not tidy *in relation to the `tidyData` as it does not have one observation per year and state. For instance:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidyData <- bind_cols( state = c('MI','CA','MI','CA'), \n                       year = c(2001, 2002, 2001, 2002),  \n                       Arrests = c(10, 21, 30, 12))\n\nnotTidyData <- bind_cols(state = c('MI','MI','MI','CA','CA','CA'), \n                         County = c('Ingham','Clinton','Wayne','Orange','Los Angeles','Kern'),\n                         InNOut_locations = c(0,0,0,20, 31, 8))\n\nhead(tidyData)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  state  year Arrests\n  <chr> <dbl>   <dbl>\n1 MI     2001      10\n2 CA     2002      21\n3 MI     2001      30\n4 CA     2002      12\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(notTidyData)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  state County      InNOut_locations\n  <chr> <chr>                  <dbl>\n1 MI    Ingham                     0\n2 MI    Clinton                    0\n3 MI    Wayne                      0\n4 CA    Orange                    20\n5 CA    Los Angeles               31\n6 CA    Kern                       8\n```\n\n\n:::\n:::\n\n\n\n\nIf we use the only common field, `state` to merge `tidyData`, which is unique on `state` and `year`, to `notTidyData`, which is unique on `county`, then every time we see `state` in our \"left\" data, we will get **all three counties in that state and for that year**. Even worse, we will get the `InNOut_locations` tally repeated for every matching `state`!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njoinedData <- left_join(tidyData, notTidyData, by = c('state'))\njoinedData\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 5\n   state  year Arrests County      InNOut_locations\n   <chr> <dbl>   <dbl> <chr>                  <dbl>\n 1 MI     2001      10 Ingham                     0\n 2 MI     2001      10 Clinton                    0\n 3 MI     2001      10 Wayne                      0\n 4 CA     2002      21 Orange                    20\n 5 CA     2002      21 Los Angeles               31\n 6 CA     2002      21 Kern                       8\n 7 MI     2001      30 Ingham                     0\n 8 MI     2001      30 Clinton                    0\n 9 MI     2001      30 Wayne                      0\n10 CA     2002      12 Orange                    20\n11 CA     2002      12 Los Angeles               31\n12 CA     2002      12 Kern                       8\n```\n\n\n:::\n:::\n\n\n\n\nBecause we asked for all columns of `tidyData` that matched (on `state`) in `notTidyData`, we get replicated `Arrests` - look at MI in 2001 in the first three rows. The original data had 10 Arrests in Michigan in 2001. Now, *for every MI County in `notTidyData`, we have replicated the statewide arrests!*\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(joinedData$Arrests)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 219\n```\n\n\n:::\n\n```{.r .cell-code}\nsum(tidyData$Arrests)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 73\n```\n\n\n:::\n:::\n\n\n\n\nYikes! We now have 3x the number of arrests in our data. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(joinedData$InNOut_locations)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 118\n```\n\n\n:::\n\n```{.r .cell-code}\nsum(notTidyData$InNOut_locations)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 59\n```\n\n\n:::\n:::\n\n\n\n\nAnd while we might like that we have 3x the In-N-Out locations, we definitely think our data shouldn't suddenly have more.\n\nThe reason this happens is that we do not have a unique *key* variable. In the `WDI` tip in Project 2, we didn't have a single unique key variable - there were multiple values of `iso2` country code in the data because we had multiple years for each `iso2`. Thus, when we merged, use used `by = c('iso2','year')` because **the `iso2` x `year` combination was the unique key**.\n\nHere, each dataset would need to have a unique key (or \"primary key\") on `state` *and* `county` *and* `year` to merge without risk of messing up our data. Since `arrests` aren't broken out by county, we'd have to use `summarize` to total `notTidyData` at the `state` and `year` (to eliminate `county`). Then, we'd have to decide of the number of In-N-Outs are the same for each `year` since `notTidyData` doesn't have `year`.\n\nThe lesson is this: always know what your join is doing. Know your unique keys. Use `sum(duplicated(tidyData$key))` to see if all values are unique, or `NROW(unique(tidyData %>% dplyr::select(key1, key2)))` to see if all rows are unique over the 2 keys (replacing \"key1\" and \"key2\" with your key fields).\n\nIf it shouldn't add rows, then make sure the new data has the same number of rows as the old one, or use `setequal` to check. \n\n\n# Parsing dates and times\n\n## The date data type\n\nWe have described three main types of vectors: numeric, character, and logical. In data science projects, we very often encounter variables that are dates. Although we can represent a date with a string, for example `November 2, 2017`, once we pick a reference day, referred to as the _epoch_, they can be converted to numbers by calculating the number of days since the epoch. Computer languages usually use January 1, 1970, as the epoch. So, for example, January 2, 2017 is day 1, December 31, 1969 is day -1, and November 2, 2017, is day 17,204.\n\nNow how should we represent dates and times when analyzing data in R? We could just use days since the epoch, but then it is almost impossible to interpret. If I tell you it's November 2, 2017, you know what this means immediately. If I tell you it's day 17,204, you will be quite confused. Similar problems arise with times and even more complications can appear due to time zones.\n\nFor this reason, `R` defines a data type just for dates and times. We saw an example in the polls data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dslabs)\ndata(\"polls_us_election_2016\")\npolls_us_election_2016$startdate %>% head\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2016-11-03\" \"2016-11-01\" \"2016-11-02\" \"2016-11-04\" \"2016-11-03\"\n[6] \"2016-11-03\"\n```\n\n\n:::\n:::\n\n\n\n\nThese look like strings, but they are not:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(polls_us_election_2016$startdate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Date\"\n```\n\n\n:::\n:::\n\n\n\n\nLook at what happens when we convert them to numbers:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.numeric(polls_us_election_2016$startdate) %>% head\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 17108 17106 17107 17109 17108 17108\n```\n\n\n:::\n:::\n\n\n\n\nIt turns them into days since the epoch. The `as.Date` function can convert a character into a date. So to see that the epoch is day 0 we can type\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.Date(\"1970-01-01\") %>% as.numeric\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\nPlotting functions, such as those in ggplot, are aware of the date format. This means that, for example, a scatterplot can use the numeric representation to decide on the position of the point, but include the string in the labels:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolls_us_election_2016 %>% dplyr::filter(pollster == \"Ipsos\" & state ==\"U.S.\") %>%\n  ggplot(aes(startdate, rawpoll_trump)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](05a_files/figure-html/rawpolls-vs-time-1.png){width=672}\n:::\n:::\n\n\n\n\nNote in particular that the month names are displayed, a very convenient feature.\n\n## The lubridate package {#lubridate}\n\nThe __tidyverse__ includes functionality for dealing with dates through the __lubridate__ package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\n```\n:::\n\n\n\n\nWe will take a random sample of dates to show some of the useful things one can do:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2002)\ndates <- sample(polls_us_election_2016$startdate, 10) %>% sort\ndates\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"2016-05-31\" \"2016-08-08\" \"2016-08-19\" \"2016-09-22\" \"2016-09-27\"\n [6] \"2016-10-12\" \"2016-10-24\" \"2016-10-26\" \"2016-10-29\" \"2016-10-30\"\n```\n\n\n:::\n:::\n\n\n\n\nThe functions `year`, `month` and `day` extract those values:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(date = dates,\n       month = month(dates),\n       day = day(dates),\n       year = year(dates))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 4\n   date       month   day  year\n   <date>     <dbl> <int> <dbl>\n 1 2016-05-31     5    31  2016\n 2 2016-08-08     8     8  2016\n 3 2016-08-19     8    19  2016\n 4 2016-09-22     9    22  2016\n 5 2016-09-27     9    27  2016\n 6 2016-10-12    10    12  2016\n 7 2016-10-24    10    24  2016\n 8 2016-10-26    10    26  2016\n 9 2016-10-29    10    29  2016\n10 2016-10-30    10    30  2016\n```\n\n\n:::\n:::\n\n\n\n\nWe can also extract the month labels:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmonth(dates, label = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] May Aug Aug Sep Sep Oct Oct Oct Oct Oct\n12 Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < Sep < ... < Dec\n```\n\n\n:::\n:::\n\n\n\n\n\nAnother useful set of functions are the _parsers_ that convert strings into dates. The function `ymd` assumes the dates are in the format YYYY-MM-DD and tries to parse as well as possible.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(20090101, \"2009-01-02\", \"2009 01 03\", \"2009-1-4\",\n       \"2009-1, 5\", \"Created on 2009 1 6\", \"200901 !!! 07\")\nymd(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2009-01-01\" \"2009-01-02\" \"2009-01-03\" \"2009-01-04\" \"2009-01-05\"\n[6] \"2009-01-06\" \"2009-01-07\"\n```\n\n\n:::\n:::\n\n\n\n\nA further complication comes from the fact that dates often come in different formats in which the order of year, month, and day are different. The preferred format is to show year (with all four digits), month (two digits), and then day, or what is called the ISO 8601. Specifically we use YYYY-MM-DD so that if we order the string, it will be ordered by date. You can see the function `ymd` returns them in this format.\n\nBut, what if you encounter dates such as \"09/01/02\"? This could be September 1, 2002 or January 2, 2009 or January 9, 2002.\nIn these cases, examining the entire vector of dates will help you determine what format it is by process of elimination. Once you know, you can use the many parses provided by __lubridate__.\n\nFor example, if the string is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- \"09/01/02\"\n```\n:::\n\n\n\n\nThe `ymd` function assumes the first entry is the year, the second is the month, and the third is the day, so it converts it to:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nymd(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2009-01-02\"\n```\n\n\n:::\n:::\n\n\n\n\nThe `mdy` function assumes the first entry is the month, then the day, then the year:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmdy(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2002-09-01\"\n```\n\n\n:::\n:::\n\n\n\n\nThe _lubridate_ package provides a function for every possibility:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nydm(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2009-02-01\"\n```\n\n\n:::\n\n```{.r .cell-code}\nmyd(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2001-09-02\"\n```\n\n\n:::\n\n```{.r .cell-code}\ndmy(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2002-01-09\"\n```\n\n\n:::\n\n```{.r .cell-code}\ndym(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2001-02-09\"\n```\n\n\n:::\n:::\n\n\n\n\nThe __lubridate__ package is also useful for dealing with times. In R base, you can get the current time typing `Sys.time()`. The __lubridate__ package provides a slightly more advanced function, `now`, that permits you to define the time zone:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnow()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2025-01-14 09:59:09 EST\"\n```\n\n\n:::\n\n```{.r .cell-code}\nnow(\"GMT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2025-01-14 14:59:09 GMT\"\n```\n\n\n:::\n:::\n\n\n\n\nYou can see all the available time zones with `OlsonNames()` function.\n\nWe can also extract hours, minutes, and seconds:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnow() %>% hour()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9\n```\n\n\n:::\n\n```{.r .cell-code}\nnow() %>% minute()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 59\n```\n\n\n:::\n\n```{.r .cell-code}\nnow() %>% second()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.763199\n```\n\n\n:::\n:::\n\n\n\n\nThe package also includes a function to parse strings into times as well as parsers for time objects that include dates:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(\"12:34:56\")\nhms(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"12H 34M 56S\"\n```\n\n\n:::\n\n```{.r .cell-code}\nx <- \"Nov/2/2012 12:34:56\"\nmdy_hms(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2012-11-02 12:34:56 UTC\"\n```\n\n\n:::\n:::\n\n\n\n\nThis package has many other useful functions. We describe two of these here that we find particularly useful.\n\nThe `make_date` function can be used to quickly create a date object. It takes three arguments: year, month, day. `make_datetime` takes the same as `make_date` but also adds hour, minute, seconds, and time zone like 'US/Michigan' but defaulting to UTC. So create an date object representing, for example, July 6, 2019 we write:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_date(2019, 7, 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2019-07-06\"\n```\n\n\n:::\n:::\n\n\n\n\nTo make a vector of January 1 for the 80s we write:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_date(1980:1989)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"1980-01-01\" \"1981-01-01\" \"1982-01-01\" \"1983-01-01\" \"1984-01-01\"\n [6] \"1985-01-01\" \"1986-01-01\" \"1987-01-01\" \"1988-01-01\" \"1989-01-01\"\n```\n\n\n:::\n:::\n\n\n\n\nAnother very useful function is the `round_date`. It can be used to _round_ dates to nearest year, quarter,  month, week, day, hour, minutes, or seconds. So if we want to group all the polls by week of the year we can do the following:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolls_us_election_2016 %>%\n  mutate(week = round_date(startdate, \"week\")) %>%\n  group_by(week) %>%\n  summarize(margin = mean(rawpoll_clinton - rawpoll_trump)) %>%\n  qplot(week, margin, data = .)\n```\n\n::: {.cell-output-display}\n![](05a_files/figure-html/poll-margin-versus-week-1.png){width=672}\n:::\n:::\n\n\n\n\nDate objects can be added to and subtracted from with `hours`, `minutes`, etc.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstartDate <- ymd_hms('2021-06-14 12:20:57')\n\nstartDate + seconds(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2021-06-14 12:21:01 UTC\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstartDate + hours(1) + days(2) - seconds(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2021-06-16 13:20:47 UTC\"\n```\n\n\n:::\n:::\n\n\n\n\nYou can even calculate time differences in specific units:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nendDate = ymd_hms('2021-06-15 01:00:00')\n\nendDate - startDate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 12.65083 hours\n```\n\n\n:::\n\n```{.r .cell-code}\ndifftime(endDate, startDate, units = 'days')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 0.5271181 days\n```\n\n\n:::\n:::\n\n\n\n\nNote that both of these result in a `difftime` object. You can use `as.numeric(difftime(endDate, startDate))` to get the numeric difference in times.\n\nSequences can be created as well:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseq(from = startDate, to = endDate, by = 'hour')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"2021-06-14 12:20:57 UTC\" \"2021-06-14 13:20:57 UTC\"\n [3] \"2021-06-14 14:20:57 UTC\" \"2021-06-14 15:20:57 UTC\"\n [5] \"2021-06-14 16:20:57 UTC\" \"2021-06-14 17:20:57 UTC\"\n [7] \"2021-06-14 18:20:57 UTC\" \"2021-06-14 19:20:57 UTC\"\n [9] \"2021-06-14 20:20:57 UTC\" \"2021-06-14 21:20:57 UTC\"\n[11] \"2021-06-14 22:20:57 UTC\" \"2021-06-14 23:20:57 UTC\"\n[13] \"2021-06-15 00:20:57 UTC\"\n```\n\n\n:::\n:::\n",
    "supporting": [
      "05a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}