{
  "hash": "8ecc95bd563bc1bf6289fb39d9f260aa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"11: LASSO\"\nduedate: \"{{< var duedates.lab11 >}}\"\n---\n\n\n\n\n\n::: {.callout-warning}\n## Due Date\nThis assignment is due on **{{< meta duedate >}}**\n:::\n\n\n\n\n{{< var blurbs.homeworkdue >}}\n\n\n\n\n\n\n\n## Oh no. Really? Ames again?\n\nYes, Ames again. Let's predict some `SalePrice`s!\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAmes <- read.table('https://raw.githubusercontent.com/ajkirkpatrick/FS20/postS21_rev/classdata/ames.csv', \n                   header = TRUE,\n                   sep = ',') %>%\n  dplyr::select(-Id)\n```\n:::\n\n\n\n\n\n\n### Data cleaning\nRepeat the data cleaning exercise from last week's lab. The point is to make sure that every observation is non-`NA` and all predictor variables have more than one value. Use `skimr::skim` on `Ames` to find predictors with only one value or are missing many values. Take them out, and use `na.omit` to ensure there are no `NA` values left. Check to make sure you still have at least 800 or so observations!\n\n### Predicive model\nFor the assignment below, we'll use `glmnet::cv.glmnet` to estimate a LASSO model. Note that you're asked to state 16 predictors and 5 interactions. You can go beyond this. **Unlike our linear model building, complexity in LASSO is not controlled by writing out a bunch of formulas with more terms. It's in the lambda parameter.** So we write one formula and let lambda vary.\n\n::: {.callout-note}\n## Exercise 1 of 1\n\n1. Clean your data as described above.\n\n2. Choose up to **16** predictor variables and clean your data so that no `NA` values are left\n\n3. Choose at least 5 interactions between your predictor variables and print out the formula you'll use to predict `SalePrice`.\n\n4. In your code, use `set.seed(24224)` so that your results will always be the same. Why do we need to set seed? When we (well, `glmnet::cvglmnet`) makes the Train and Test sample(s), it'll select them randomly. If you don't set seed, every time you run it, you'll get slightly different answers!\n\n5. Using `glmnet::cv.glmnet` to estimate a LASSO model (see lecture notes this week) that predicts `SalePrice` given the observed data and using your formula. Slide 33 shows cross-validation using both `alpha` and `lambda` -- a LASSO model holds `alpha` fixed at `alpha = 1`. We'll search using `lambda` as our tuning parameter. Call the resulting object `net_cv`.\n\n- To do this, you'll have to make a matrix to give to `cv.glmnet` in the `x` argument because it doesn't take a formula. You can use `model.matrix()` to create the matrix. Use that matrix as your `x`. It will not add the `SalePrice` variable to the `x` matrix -- you just have to give it `SalePrice` as the `y` variable.\n\n6. The resulting object will be a `glmnet` object. You can see the optimal lambda just by printing the object `print(net_cv)` and looking at the min value for Lambda. **Make sure the optimal (RMSE-minimizing) value of lambda is not the largest or smallest value of lambda you gave it**. If it is, then extend the range of lambdas until you get an interior solution. Following the instructions from our lecture note's **TRY IT**, extract the lambdas and their respective RMSE values into a data.frame and make a plot similar to the RMSE plot from lecture.\n\n7. Answer the following question: What is the optimal `lambda` based on the plot/data? Do you see a minimum point in the plot?\n\n8. Extracting the non-zero coefficients is a little tricky, but let's do it. We'll use the `coef` function to extract the coefficients. The `coef` function, when used on a `glmnet` object, takes the argument `s` which is the `lambda` value for which you'd like to extract coefficients. Our `s` value should be the best value of lambda, which we can extract from `net_cv$lambda.min`. Put those together: `coef(net_cv, s = net_cv$lambda.min)`. **This may be kinda long, that's OK**.\n\n\n:::\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}