---
title: "9: LASSO"
duedate: "{{< var duedates.lab9 >}}"
---


::: {.callout-warning}
## Due Date
This assignment is due on **{{< meta duedate >}}**
:::

{{< var blurbs.homeworkdue >}}


## Oh no. Really? Ames again?

Yes, Ames again. Let's predict some `SalePrice`s!


```{r}

Ames <- read.table('https://raw.githubusercontent.com/ajkirkpatrick/FS20/postS21_rev/classdata/ames.csv', 
                   header = TRUE,
                   sep = ',') %>%
  dplyr::select(-Id)
```


```{r, include=F, eval=F}
library(caret); library(glmnet)


Amesuse = Ames %>% 
  dplyr::select(-FireplaceQu, -PoolQC, -Fence, -MiscFeature, -Alley,
                -Utilities) %>%
  na.omit()


  lambdas = 10^seq(from = 4, to = -2, length = 100)
  # Our range of alpha
  alphas = seq(from = 0, to = 1, by = 0.1)

  
net_cv = train(
  # The formula
  SalePrice ~ .,
  # The dataset
  data = Amesuse,
  # The 'glmnet' package does ridge and lasso
  method = "glmnet",
  metric = 'RMSE',
  # 5-fold cross validation
  trControl = trainControl("cv", number = 10),
  # The parameters of 'glmnet'
  tuneGrid = expand.grid(alpha = 1, lambda = lambdas)
)



ggplot(res, aes(x = lambda, y = mse)) + 
  geom_path()


coef(net_cv$finalModel, s = net_cv$finalModel$lambdaOpt)


```

### Data cleaning
Repeat the data cleaning exercise from last week's lab. The point is to make sure that every observation is non-`NA` and all predictor variables have more than one value. Use `skimr::skim` on `Ames` to find predictors with only one value or are missing many values. Take them out, and use `na.omit` to ensure there are no `NA` values left. Check to make sure you still have at least 800 or so observations!

::: {.callout-note}
## Exercise 1 of 1

1. Clean your data as described above.

2. Choose up to **16** predictor variables and clean your data so that no `NA` values are left

3. Choose at least 5 interactions between your predictor variables and print out the formula you'll use to predict `SalePrice`

4. In your code, use `set.seed(24224)` so that your results will always be the same. Why do we need to set seed? When we (well, `caret::train`) makes the Train and Test sample(s), it'll select them randomly. If you don't set seed, every time you run it, you'll get slightly different answers!

5. Using `caret::train` to estimate a LASSO model (see lecture notes this week, slide 41) that predicts `SalePrice` given the observed data and using your formula. Slide 41 shows cross-validation using both `alpha` and `lambda` -- a LASSO model holds `alpha` fixed at `alpha = 1`. We'll search using `lambda` as our tuning parameter. Call the resulting object `net_cv`.

6. The resulting object will be a list which has a data.frame called `net_cv$result`. Use that to make a plot with `lambda` on the X-axis and `RMSE` on the Y-axis. You may have to use `+ coord_cartesian(xlim = c(0,...))` with a proper upper limit to limit the x-axis in `ggplot` to see the RMSE minimum, depending on the range of `lambda` you used.

7. Answer the following question: What is the optimal `lambda` based on the plot/data? `net_cv$finalModel$lambdaOpt` will return the optimal tuning parameters. Does that match your plot? 

8. Extracting the non-zero coefficients is a little tricky, but let's do it. The object `net_cv$finalModel` will be *all* of models (one for each `lambda`) for the "best" value of alpha. We set `alpha=1` for LASSO, so the best alpha is...alpha=1. The `coef` function, when used on a `train` object, takes the argument `s` which is the `lambda` value you'd like to extract coefficients. Our `s` value should be the best value of lambda, which we can extract from `net_cv$finalModel$lambdaOpt`. Put those together: `coef(net_cv$finalModel, s = net_cv$finalModel$lambdaOpt)`. **This may be kinda long, that's OK. It's showing you all of the variables it tried, and which ones were kept by LASSO**.

:::




