{
  "hash": "7761593a1026dfbc3da378541006b64c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Text as Data\"\n\n---\n\n\n\n\n## Required Reading\n\n- This page.\n\n### Guiding Questions\n\n- What are some common issues with string data? \n- What are the key ways to wrangle strings?\n- What are _regular expressions_ and why are they magic \n\n\n# String processing\n\n\n\n\n\n\n\n\n\n\nOne of the most common data wrangling challenges involves extracting numeric data contained in character strings and converting them into the numeric representations required to make plots, compute summaries, or fit models in R. Also common is processing unorganized text into meaningful variable names or categorical variables. Many of the string processing challenges a data scientist faces are unique and often unexpected. It is therefore quite ambitious to write a comprehensive section on this topic. Here we use a series of case studies that help us demonstrate how string processing is a necessary step for many data wrangling challenges. Specifically, we describe the process of converting the not yet shown original _raw_ data from which we extracted the `murders`, `heights`, and `research_funding_rates` example into the data frames we have studied in this book.\n\nBy going over these case studies, we will cover some of the most common tasks in string processing including\nextracting numbers from strings,\nremoving unwanted characters from text,\nfinding and replacing characters,\nextracting specific parts of strings,\nconverting free form text to more uniform formats, and\nsplitting strings into multiple values.\n\n\nBase R includes functions to perform all these tasks. However, they don't follow a unifying convention, which makes them a bit hard to memorize and use. The __stringr__ package basically repackages this functionality, but uses a more consistent approach of naming functions and ordering their arguments. For example, in __stringr__, all the string processing functions start with `str_`. This means that if you type `str_` and hit tab, R will auto-complete and show all the available functions. As a result, we don't necessarily have to memorize all the function names. Another advantage is that in the functions in this package the string being processed is always the first argument, which means we can more easily use the pipe. Therefore, we will start by describing how to use the functions in the  __stringr__ package.\n\nMost of the examples will come from the second case study which deals with self-reported heights by students and most of the chapter is dedicated to learning regular expressions (regex), and functions in the __stringr__ package.\n\n\n## The stringr package\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(stringr)\n```\n:::\n\n\n\nIn general, string processing tasks can be divided into **detecting**, **locating**, **extracting**, or **replacing** patterns in strings. We will see several examples. The table below includes the functions available to you in the __stringr__ package. We split them by task. We also include the R-base equivalent when available.\n\nAll these functions take a character vector as first argument. Also, for each function, operations are vectorized: the operation gets applied to each string in the vector.\n\nFinally, note that in this table we mention _groups_. These will be explained later on.\n\n | stringr     | Task     | Description                              | R-base |\n|--------------- |----------|--------------------------------------|-------------|\n| `str_detect` | Detect | Is the pattern in the string? | `grepl` |\n| `str_which` | Detect | Returns the index of entries that contain the pattern. |  `grep` |\n| `str_subset` | Detect | Returns the subset of strings that contain the pattern. | `grep` with `value = TRUE` |\n| `str_locate` | Locate | Returns positions of first occurrence of pattern in a string.| `regexpr` |\n|  `str_locate_all` | Locate | Returns position of all occurrences of pattern in a string. |`gregexpr` |\n| `str_view` | Locate | Show the first part of the string that matches pattern. | |\n | `str_view_all` | Locate | Show me all the parts of the string that match the pattern. |\n| `str_extract` | Extract | Extract the first part of the string that matches the pattern. | |\n`str_extract_all` | Extract | Extract all parts of the string that match the pattern. |  |\n | `str_match` | Extract | Extract first part of the string that matches the groups and the patterns defined by the groups.| |\n| `str_match_all` | Extract | Extract all parts of the string that matches the groups and the patterns defined by the groups. | |\n| `str_sub` | Extract | Extract a substring. | `substring` |\n| `str_split` | Extract | Split a string into a list with parts separated by pattern. | `strsplit`|\n| `str_split_fixed` | Extract | Split a string into a matrix with parts separated by pattern. | `strsplit` with `fixed = TRUE`|\n| `str_count` | Describe | Count number of times a pattern appears in a string.  |   |\n| `str_length`| Describe | Number of character in string.  | `nchar` |\n| `str_replace` | Replace | Replace first part of a string matching a pattern with another.  | |\n| `str_replace_all`| Replace | Replace all parts of a string matching a pattern with another.  | `gsub` |\n | `str_to_upper` | Replace | Change all characters to upper case. | `toupper` |\n| `str_to_lower` | Replace | Change all characters to lower case. | `tolower` |\n| `str_to_title` | Replace | Change first character to upper and rest to lower. | |\n | `str_replace_na`| Replace | Replace all `NA`s to a new value. | |\n| `str_trim` | Replace | Remove white space from start and end of string. | |\n| `str_c`| Manipulate | Join multiple strings.  | `paste0` |\n | `str_conv` | Manipulate | Change the encoding of the string.| |\n | `str_sort` | Manipulate | Sort the vector in alphabetical order.| `sort` |\n | `str_order`| Manipulate | Index needed to order the vector in alphabetical order. | `order` |\n| `str_trunc` | Manipulate | Truncate a string to a fixed size. | |\n| `str_pad`| Manipulate | Add white space to string to make it a fixed size.  | |\n| `str_dup`| Manipulate | Repeat a string.  | `rep` then `paste` |\n | `str_wrap` | Manipulate | Wrap things into formatted paragraphs. | |\n| `str_interp` | Manipulate | String interpolation. |  `sprintf` |\n\n\n## Case study 1: US murders data\n\n\nIn this section we introduce some of the more simple string processing challenges with the following datasets as an example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nurl <- paste0(\"https://en.wikipedia.org/w/index.php?title=\",\n              \"Gun_violence_in_the_United_States_by_state\",\n              \"&direction=prev&oldid=810166167\")\nmurders_raw <- read_html(url) %>%\n  html_node(\"table\") %>%\n  html_table() %>%\n  setNames(c(\"state\", \"population\", \"total\", \"murder_rate\"))\n\nhead(murders_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  state      population total murder_rate\n  <chr>      <chr>      <chr>       <dbl>\n1 Alabama    4,853,875  348           7.2\n2 Alaska     737,709    59            8  \n3 Arizona    6,817,565  309           4.5\n4 Arkansas   2,977,853  181           6.1\n5 California 38,993,940 1,861         4.8\n6 Colorado   5,448,819  176           3.2\n```\n\n\n:::\n:::\n\n\n\n\nThe code above shows the first step in constructing the dataset\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dslabs)\ndata(murders)\n```\n:::\n\n\n\n\nfrom the raw data, which was extracted from a Wikipedia page. \n\nIn general, string processing involves a string and a pattern. In R, we usually store strings in a character vector such as `murders$population`. The first three strings in this vector defined by the population variable are:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmurders_raw$population[1:3]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"4,853,875\" \"737,709\"   \"6,817,565\"\n```\n\n\n:::\n:::\n\n\n\n\nThe usual coercion does not work here:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.numeric(murders_raw$population[1:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] NA NA NA\n```\n\n\n:::\n:::\n\n\n\n\nThis is because of the commas `,`. The string processing we want to do here is remove the **pattern**, `,`, from the **strings** in `murders_raw$population` and then coerce to numbers.\nWe can use the `str_detect` function to see that two of the three columns have commas in the entries:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommas <- function(x) any(str_detect(x, \",\"))\nmurders_raw %>% summarize_all(commas)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  state population total murder_rate\n  <lgl> <lgl>      <lgl> <lgl>      \n1 FALSE TRUE       TRUE  FALSE      \n```\n\n\n:::\n:::\n\n\n\n\nWe can then use the `str_replace_all` function to remove them:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_1 <- str_replace_all(murders_raw$population, \",\", \"\")\ntest_1 <- as.numeric(test_1)\n```\n:::\n\n\n\n\nThe `stringr` function `str_replace_all` replaces all of the first argument's instances of `,` (the second argument) with `''` (the third argument). The first input for the function is the character vector on which you'd like to operate.\n\nWe can then use `mutate_all` to apply this operation to each column, since it won't affect the columns without commas. You may notice the use of `mutate_all` and `summarize_all` here. These are versions of `mutate` and `summarize` that apply a given *function* to every column in the data. Above, the function we apply to every column is the `commas` function. Note that in using `summarize_all` we pipe the data in, but we *do not list the columns* we wish to create via `summarize`. To apply `as.numeric` to each column in `murders_raw`, we'd use: `murders_raw %>% mutate_all(str_replace_all, ',', '') %>% mutate_at(2:3, as.numeric)`. \n\n**Note, the `str_replace_all` function is NOT an analog to `mutate_all` that applies to each column in the data!**\n\nIt turns out that this operation is so common that `readr` includes the function `parse_number` specifically meant to remove non-numeric characters before coercing:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_2 <- parse_number(murders_raw$population)\nidentical(test_1, test_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\nSo we can obtain our desired table using:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmurders_new <- murders_raw %>% mutate_at(2:3, parse_number)\nhead(murders_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  state      population total murder_rate\n  <chr>           <dbl> <dbl>       <dbl>\n1 Alabama       4853875   348         7.2\n2 Alaska         737709    59         8  \n3 Arizona       6817565   309         4.5\n4 Arkansas      2977853   181         6.1\n5 California   38993940  1861         4.8\n6 Colorado      5448819   176         3.2\n```\n\n\n:::\n:::\n\n\n\n\nThis case is relatively simple compared to the string processing challenges that we typically face in data science. The next example is a rather complex one and it provides several challenges that will permit us to learn many string processing techniques.\n\n## Case study 2: self-reported heights\n\nThe __dslabs__ package includes the raw data from which the heights dataset was obtained. You can load it like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(reported_heights)\n```\n:::\n\n\n\n\nThese heights were obtained using a web form in which students were asked to enter their heights. They could enter anything, but the instructions asked for _height in inches_, a number. We compiled 1,095 submissions, but unfortunately the column vector with the reported heights had several non-numeric entries and as a result became a character vector:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(reported_heights$height)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"character\"\n```\n\n\n:::\n:::\n\n\n\n\nIf we try to parse it into numbers, we get a warning:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- as.numeric(reported_heights$height)\n```\n:::\n\n\n\n\nAlthough most values appear to be height in inches as requested:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 75 70 68 74 61 65\n```\n\n\n:::\n:::\n\n\n\n\nwe do end up with many `NA`s:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 81\n```\n\n\n:::\n:::\n\n\n\n\nWe can see some of the entries that are not successfully converted by using `filter` to keep only the entries resulting in `NA`s:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreported_heights %>%\n  dplyr::mutate(new_height = as.numeric(height)) %>%\n  dplyr::filter(is.na(new_height)) %>%\n  head(n=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            time_stamp    sex                 height new_height\n1  2014-09-02 15:16:28   Male                  5' 4\"         NA\n2  2014-09-02 15:16:37 Female                  165cm         NA\n3  2014-09-02 15:16:52   Male                    5'7         NA\n4  2014-09-02 15:16:56   Male                  >9000         NA\n5  2014-09-02 15:16:56   Male                   5'7\"         NA\n6  2014-09-02 15:17:09 Female                   5'3\"         NA\n7  2014-09-02 15:18:00   Male 5 feet and 8.11 inches         NA\n8  2014-09-02 15:19:48   Male                   5'11         NA\n9  2014-09-04 00:46:45   Male                  5'9''         NA\n10 2014-09-04 10:29:44   Male                 5'10''         NA\n```\n\n\n:::\n:::\n\n\n\n\nWe immediately see what is happening. Some of the students did not report their heights in inches as requested. We could discard these data and continue. However, many of the entries follow patterns that, in principle, we can easily convert to inches. For example, in the output above, we see various cases that use the format `x'y''` with `x` and `y` representing feet and inches, respectively. Each one of these cases can be read and converted to inches by a human, for example `5'4''` is `5*12 + 4 = 64`. So we could fix all the problematic entries _by hand_. However, humans are prone to making mistakes, so an automated approach is preferable. Also, because we plan on continuing to collect data, it will be convenient to write code that automatically does this.\n\nA first step in this type of task is to survey the problematic entries and try to define specific patterns followed by a large groups of entries. The larger these groups, the more entries we can fix with a single programmatic approach. We want to find patterns that can be accurately described with a rule, such as \"a digit, followed by a feet symbol, followed by one or two digits, followed by an inches symbol\".\n\nTo look for such patterns, it helps to remove the entries that are consistent with being in inches and to view only the problematic entries. We thus write a function to automatically do this. We keep entries that either result in `NA`s when applying `as.numeric` or are outside a range of plausible heights. We permit a range that covers about 99.9999% of the adult population. We also use `suppressWarnings` to avoid the warning message we know `as.numeric` will gives us.\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnot_inches <- function(x, smallest = 50, tallest = 84){\n  inches <- suppressWarnings(as.numeric(x))\n  ind <- is.na(inches) | inches < smallest | inches > tallest\n  ind\n}\n```\n:::\n\n\n\n\nWe apply this function and find the number of problematic entries:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproblems <- reported_heights %>%\n  dplyr::filter(not_inches(height)) %>%\n  pull(height)\nlength(problems)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 292\n```\n\n\n:::\n:::\n\n\n\n\n \nWe can now view all the cases by simply printing them. We don't do that here because there are 292 problems, but after surveying them carefully, we see that three patterns can be used to define three large groups within these exceptions.\n\n1\\. A pattern of the form `x'y` or `x' y''` or `x'y\"` with `x` and `y` representing feet and inches, respectively. Here are ten examples:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n5' 4\" 5'7 5'7\" 5'3\" 5'11 5'9'' 5'10'' 5' 10 5'5\" 5'2\"\n```\n\n\n:::\n:::\n\n\n\n\n2\\. A pattern of the form `x.y` or `x,y` with `x` feet and `y` inches. Here are ten examples:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n5.3 5.5 6.5 5.8 5.6 5,3 5.9 6,8 5.5 6.2\n```\n\n\n:::\n:::\n\n\n\n\n\n3\\. Entries that were reported in centimeters rather than inches. Here are ten examples:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n150 175 177 178 163 175 178 165 165 180\n```\n\n\n:::\n:::\n\n\n\n\nOnce we see these large groups following specific patterns, we can develop a plan of attack. Remember that there is rarely just one way to perform these tasks. Here we pick one that helps us teach several useful techniques. But surely there is a more efficient way of performing the task.\n\n**Plan of attack**: we will convert entries fitting the first two patterns into a standardized one. We will then leverage the standardization to extract the feet and inches and convert to inches. We will then define a procedure for identifying entries that are in centimeters and convert them to inches. After applying these steps, we will then check again to see what entries were not fixed and see if we can tweak our approach to be more comprehensive.\n\nAt the end, we hope to have a script that makes web-based data collection methods robust to the most common user mistakes.\n\nTo achieve our goal, we will use a technique that enables us to accurately detect patterns and extract the parts we want:  _regular expressions_ (regex). But first, we quickly describe how to _escape_ the function of certain characters so that they can be included in strings.\n\n\n## How to _escape_ when defining strings\n\nTo define strings in R, we can use either double quotes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- \"Hello!\"\n```\n:::\n\n\n\n\nor single quotes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- 'Hello!'\n```\n:::\n\n\n\n\nMake sure you choose the correct single quote since using the back quote will give you an error:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- `Hello`\n```\n:::\n\n\n\n```\nError: object 'Hello' not found\n```\n\nNow, what happens if the string we want to define includes double quotes? For example, if we want to write 10 inches like this `10\"`?\nIn this case you can't use:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- \"10\"\"\n```\n:::\n\n\n\n\nbecause this is just the string `10` followed by a double quote. If you type this into R, you get an error because you have an _unclosed_ double quote. To avoid this, we can use the single quotes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- '10\"'\n```\n:::\n\n\n\n\nIf we print out `s` we see that the double quotes are _escaped_ with the backslash `\\`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"10\\\"\"\n```\n\n\n:::\n:::\n\n\n\n\nIn fact, escaping with the backslash provides a way to define the string while still using the double quotes to define strings:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- \"10\\\"\"\n```\n:::\n\n\n\n\nIn R, the function `cat` lets us see what the string actually looks like:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n10\"\n```\n\n\n:::\n:::\n\n\n\n\nNow, what if we want our string to be 5 feet written like this `5'`? In this case, we can use the double quotes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- \"5'\"\ncat(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5'\n```\n\n\n:::\n:::\n\n\n\n\nSo we've learned how to write 5 feet and 10 inches separately, but what if we want to write them together to represent _5 feet and 10 inches_ like this `5'10\"`? In this case, neither the single nor double quotes will work. This:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- '5'10\"'\n```\n:::\n\n\n\n\ncloses the string after 5 and this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- \"5'10\"\"\n```\n:::\n\n\n\ncloses the string after 10. Keep in mind that if we type one of the above code snippets into R, it will get stuck waiting for you to close the open quote and you will have to exit the execution with the _esc_ button.\n\nIn this situation, we need to escape the function of the quotes with the backslash `\\`. You can escape either character like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- '5\\'10\"'\ncat(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5'10\"\n```\n\n\n:::\n:::\n\n\n\n\nor like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- \"5'10\\\"\"\ncat(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n5'10\"\n```\n\n\n:::\n:::\n\n\n\n\nEscaping characters is something we often have to use when processing strings. \n\n## Regular expressions\n\nA regular expression (regex) is a way to describe specific patterns of characters of text. They can be used to determine if a given string matches the pattern. A set of rules has been defined to do this efficiently and precisely and here we show some examples. We can learn more about these rules by reading a detailed tutorials^[https://www.regular-expressions.info/tutorial.html] ^[http://r4ds.had.co.nz/strings.html#matching-patterns-with-regular-expressions]. This RStudio cheat sheet^[https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf] is also very useful.\n\n\nThe patterns supplied to the __stringr__ functions can be a regex rather than a standard string. We will learn how this works through a series of examples.\n\nThroughout this section you will see that we create strings to test out our regex. To do this, we define patterns that we know should match and also patterns that we know should not. We will call them `yes` and `no`, respectively. This permits us to check for the two types of errors: failing to match and incorrectly matching.\n\n\n### Strings are a regex\n\nTechnically any string is a regex, perhaps the simplest example is a single character. So the comma `,` used in the next code example is a simple example of searching with regex.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \",\"\nstr_detect(murders_raw$total, pattern)\n```\n:::\n\n\n\n\nWe suppress the output which is logical vector telling us which entries have commas.\n\nAbove, we noted that an entry included a `cm`. This is also a simple example of a regex. We can show all the entries that used `cm` like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_subset(reported_heights$height, \"cm\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"165cm\"  \"170 cm\"\n```\n\n\n:::\n:::\n\n\n\n\n### Special characters\n\nNow let's consider a slightly more complicated example. Which of the following strings contain the pattern `cm` or `inches`?\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- c(\"180 cm\", \"70 inches\")\nno <- c(\"180\", \"70''\")\ns <- c(yes, no)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_detect(s, \"cm\") | str_detect(s, \"inches\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE  TRUE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nHowever, we don't need to do this. The main feature that distinguishes the regex _language_ from plain strings is that we can use special characters. These are characters with a meaning. We start by introducing `|` which means _or_.  So if we want to know if either `cm` or `inches` appears in the strings, we can use the regex `cm|inches`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_detect(s, \"cm|inches\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE  TRUE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nand obtain the correct answer.\n\nAnother special character that will be useful for identifying feet and inches values is `\\d` which means any digit: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. The backslash is used to distinguish it from the character `d`. In R, we have to _escape_ the backslash `\\` so we actually have to use `\\\\d` to represent digits. Here is an example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- c(\"5\", \"6\", \"5'10\", \"5 feet\", \"4'11\")\nno <- c(\"\", \".\", \"Five\", \"six\")\ns <- c(yes, no)\npattern <- \"\\\\d\"\nstr_detect(s, pattern)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nWe take this opportunity to introduce the `str_view` function, which is helpful for troubleshooting as it shows us the first match for each string:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_view(s, pattern)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/str_view-1.png){width=668}\n:::\n:::\n\n\n\n\n\nand `str_view_all` shows us all the matches, so `3'2` has two matches and `5'10` has three.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_view_all(s, pattern)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/str_view-2.png){width=737}\n:::\n:::\n\n\n\n\nThere are many other special characters. We will learn some others below, but you can see most or all of them in the cheat sheet^[https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf] mentioned earlier.\n\n\n### Character classes\n\nCharacter classes are used to define a series of characters that can be matched. We define character classes with square brackets `[]`. So, for example, if we want the pattern to match only if we have a `5` or a `6`, we use the regex `[56]`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_view(s, \"[56]\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/str_view-3.png){width=693}\n:::\n:::\n\n\n\n\n\nSuppose we want to match values between 4 and 7. A common way to define character classes is with ranges.  So, for example, `[0-9]` is equivalent to `\\\\d`. The pattern we want is therefore `[4-7]`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- as.character(4:7)\nno <- as.character(1:3)\ns <- c(yes, no)\nstr_detect(s, \"[4-7]\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nHowever, it is important to know that in regex everything is a character; there are no numbers. So `4` is the character `4` not the number four. Notice, for example, that `[1-20]` does **not** mean 1 through 20, it means the characters 1 through 2 or the character 0. So `[1-20]` simply means the character class composed of 0, 1, and 2.\n\nKeep in mind that characters do have an order and the digits do follow the numeric order. So `0` comes before `1` which comes before `2` and so on. For the same reason, we can define lower case letters as `[a-z]`, upper case letters as `[A-Z]`, and `[a-zA-z]` as both.\n\n### Anchors\n\nWhat if we want a match when we have exactly 1 digit? This will be useful in our case study since feet are never more than 1 digit so a restriction will help us. One way to do this with regex is by using _anchors_, which let us define patterns that must start or end at a specific place. The two most common anchors are\n`^` and `$` which represent the beginning and end of a string, respectively. So the pattern `^\\\\d$` is read as \"start of the string followed by one digit followed by end of string\".\n\nThis pattern now only detects the strings with exactly one digit:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^\\\\d$\"\nyes <- c(\"1\", \"5\", \"9\")\nno <- c(\"12\", \"123\", \" 1\", \"a4\", \"b\")\ns <- c(yes, no)\nstr_view_all(s, pattern)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/str_view-4.png){width=736}\n:::\n:::\n\n\n\n\n\n\nThe ` 1` does not match because it does not start with the digit but rather with a space, which is actually not easy to see.\n\n### Quantifiers\n\nFor the inches part, we can have one or two digits. This can be specified in regex with _quantifiers_. This is done by following the pattern with curly brackets containing the number of times the previous entry can be repeated. We use an example to illustrate. The pattern for one or two digits is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^\\\\d{1,2}$\"\nyes <- c(\"1\", \"5\", \"9\", \"12\")\nno <- c(\"123\", \"a4\", \"b\")\nstr_view(c(yes, no), pattern)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/str_view-5.png){width=721}\n:::\n:::\n\n\n\n\n\nIn this case, `123` does **not** match, but `12` does. So  to look for our feet and inches pattern, we can add the symbols for feet `'` and inches `\"` after the digits.\n\n\nWith what we have learned, we can now construct an example for the pattern `x'y\\\"` with `x` feet and `y` inches.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^[4-7]'\\\\d{1,2}\\\"$\"\n```\n:::\n\n\n\n\n\nThe pattern is now getting complex, but you can look at it carefully and break it down:\n\n- `^` = start of the string\n- `[4-7]` = one digit, either 4,5,6 or 7\n- `'` = feet symbol\n- `\\\\d{1,2}` = one or two digits\n- `\\\"` = inches symbol\n- `$` = end of the string\n\nLet's test it out:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- c(\"5'7\\\"\", \"6'2\\\"\",  \"5'12\\\"\")\nno <- c(\"6,2\\\"\", \"6.2\\\"\",\"I am 5'11\\\"\", \"3'2\\\"\", \"64\")\nstr_detect(yes, pattern)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE TRUE TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_detect(no, pattern)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE FALSE FALSE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nFor now, we are permitting the inches to be 12 or larger. We will add a restriction later as the regex for this is a bit more complex than we are ready to show.\n\n### White space `\\s`\n\nAnother problem we have are spaces. For example, our pattern  does not match `5' 4\"` because there is a space between `'` and `4` which our pattern does not permit. Spaces are characters and R does not ignore them:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidentical(\"Hi\", \"Hi \")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\n\nIn regex, `\\s` represents white space. To find patterns like `5' 4`, we can change our pattern to:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern_2 <- \"^[4-7]'\\\\s\\\\d{1,2}\\\"$\"\nstr_subset(problems, pattern_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5' 4\\\"\"  \"5' 11\\\"\" \"5' 7\\\"\" \n```\n\n\n:::\n:::\n\n\n\n\nHowever, this will not match the patterns with no space. So do we need more than one regex pattern?  It turns out we can use a quantifier for this as well.\n\n### Quantifiers: `*`, `?`, `+`\n\nWe want the pattern to permit spaces but not require them. Even if there are several spaces, like in this example `5'   4`, we still want it to match. There is a quantifier for exactly this purpose. In regex, the character `*` means  zero or more instances of the previous character. Here is an example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- c(\"AB\", \"A1B\", \"A11B\", \"A111B\", \"A1111B\")\nno <- c(\"A2B\", \"A21B\")\nstr_detect(yes, \"A1*B\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE TRUE TRUE TRUE TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_detect(no, \"A1*B\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nThe above matches the first string which has zero 1s and all the strings with one or more 1. We can then improve our pattern by adding the `*` after the space character `\\s`.\n\nThere are two other similar quantifiers. For none or once, we can use `?`, and for one or more, we can use `+`. You can see how they differ with this example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(string = c(\"AB\", \"A1B\", \"A11B\", \"A111B\", \"A1111B\"),\n           none_or_more = str_detect(yes, \"A1*B\"),\n           nore_or_once = str_detect(yes, \"A1?B\"),\n           once_or_more = str_detect(yes, \"A1+B\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  string none_or_more nore_or_once once_or_more\n1     AB         TRUE         TRUE        FALSE\n2    A1B         TRUE         TRUE         TRUE\n3   A11B         TRUE        FALSE         TRUE\n4  A111B         TRUE        FALSE         TRUE\n5 A1111B         TRUE        FALSE         TRUE\n```\n\n\n:::\n:::\n\n\n\n\nWe will actually use all three in our reported heights example, but we will see these in a later section.\n\n### Not\n\nTo specify patterns that we do **not** want to detect, we can use the `^` symbol but only __inside__ square brackets. Remember that outside the square bracket `^` means the start of the string. So, for example, if we want to detect digits that are preceded by anything except a letter we can do the following:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"[^a-zA-Z]\\\\d\"\nyes <- c(\".3\", \"+2\", \"-0\",\"*4\")\nno <- c(\"A3\", \"B2\", \"C0\", \"E4\")\nstr_detect(yes, pattern)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE TRUE TRUE TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_detect(no, pattern)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE FALSE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nAnother way to generate a pattern that searches for _everything except_ is to use the upper case of the special character. For example `\\\\D` means anything other than a digit, `\\\\S` means anything except a space, and so on.\n\n### Groups\n\n_Groups_ are a powerful aspect of regex that permits the extraction of values. Groups are defined using parentheses. They don't affect the pattern matching per se. Instead, it permits tools to identify specific parts of the pattern so we can extract them.\n\nWe want to change heights written like `5.6` to `5'6`.\n\nTo avoid changing patterns such as `70.2`, we will require that the first digit be between 4 and 7 `[4-7]` and that the second be none or more digits `\\\\d*`.\nLet's start by defining a simple pattern that matches this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern_without_groups <- \"^[4-7],\\\\d*$\"\n```\n:::\n\n\n\n\nWe want to extract the digits so we can then form the new version using a period. These are our two groups, so we encapsulate them with parentheses:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern_with_groups <-  \"^([4-7]),(\\\\d*)$\"\n```\n:::\n\n\n\n\nWe encapsulate the part of the pattern that matches the parts we want to keep for later use. Adding groups does not affect the detection, since it only signals that we want to save what is captured by the groups. Note that both patterns return the same result when using `str_detect`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- c(\"5,9\", \"5,11\", \"6,\", \"6,1\")\nno <- c(\"5'9\", \",\", \"2,8\", \"6.1.1\")\ns <- c(yes, no)\nstr_detect(s, pattern_without_groups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_detect(s, pattern_with_groups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\nOnce we define groups, we can use the function `str_match` to extract the values these groups define:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_match(s, pattern_with_groups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]   [,2] [,3]\n[1,] \"5,9\"  \"5\"  \"9\" \n[2,] \"5,11\" \"5\"  \"11\"\n[3,] \"6,\"   \"6\"  \"\"  \n[4,] \"6,1\"  \"6\"  \"1\" \n[5,] NA     NA   NA  \n[6,] NA     NA   NA  \n[7,] NA     NA   NA  \n[8,] NA     NA   NA  \n```\n\n\n:::\n:::\n\n\n\n\nNotice that the second and third columns contain feet and inches, respectively. The first column is the part of the string matching the pattern. If no match occurred, we see an `NA`.\n\nNow we can understand the difference between the functions `str_extract` and `str_match`:  `str_extract` extracts only strings that match a pattern, not the values defined by groups:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_extract(s, pattern_with_groups)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5,9\"  \"5,11\" \"6,\"   \"6,1\"  NA     NA     NA     NA    \n```\n\n\n:::\n:::\n\n\n\n\n\n## Search and replace with regex\n\nEarlier we defined the object `problems` containing the strings that do not appear to be in inches.  We can see that not too many of our problematic strings match the pattern:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^[4-7]'\\\\d{1,2}\\\"$\"\nsum(str_detect(problems, pattern))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14\n```\n\n\n:::\n:::\n\n\n\n\nTo see why this is, we show some examples that expose why we don't have more matches:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproblems[c(2, 10, 11, 12, 15)] %>% str_view(pattern)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/str_view-6.png){width=723}\n:::\n:::\n\n\n\n\n\n\nAn initial problem we see immediately is that some students wrote out the words \"feet\" and \"inches\". We can see the entries that did this with the `str_subset` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_subset(problems, \"inches\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5 feet and 8.11 inches\" \"Five foot eight inches\" \"5 feet 7inches\"        \n[4] \"5ft 9 inches\"           \"5 ft 9 inches\"          \"5 feet 6 inches\"       \n```\n\n\n:::\n:::\n\n\n\n\nWe also see that some entries used two single quotes `''` instead of a double quote `\"`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_subset(problems, \"''\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"5'9''\"   \"5'10''\"  \"5'10''\"  \"5'3''\"   \"5'7''\"   \"5'6''\"   \"5'7.5''\"\n [8] \"5'7.5''\" \"5'10''\"  \"5'11''\"  \"5'10''\"  \"5'5''\"  \n```\n\n\n:::\n:::\n\n\n\n\nTo correct this, we can replace the different ways of representing inches and feet with a uniform symbol. We will use `'` for feet, whereas for inches we will simply not use a symbol since some entries were of the form `x'y`. Now, if we no longer use the inches symbol, we have to change our pattern accordingly:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^[4-7]'\\\\d{1,2}$\"\n```\n:::\n\n\n\n\nIf we do this replacement before the matching, we get many more matches:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproblems %>%\n  str_replace(\"feet|ft|foot\", \"'\") %>% # replace feet, ft, foot with '\n  str_replace(\"inches|in|''|\\\"\", \"\") %>% # remove all inches symbols\n  str_detect(pattern) %>%\n  sum()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 48\n```\n\n\n:::\n:::\n\n\n\n\nHowever, we still have many cases to go.\n\nNote that in the code above, we leveraged the __stringr__ consistency and used the pipe.\n\nFor now, we improve our pattern by adding `\\\\s*` in front of and after the feet symbol `'` to permit space between the feet symbol and the numbers. Now we match a few more entries:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^[4-7]\\\\s*'\\\\s*\\\\d{1,2}$\"\nproblems %>%\n  str_replace(\"feet|ft|foot\", \"'\") %>% # replace feet, ft, foot with '\n  str_replace(\"inches|in|''|\\\"\", \"\") %>% # remove all inches symbols\n  str_detect(pattern) %>%\n  sum\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 53\n```\n\n\n:::\n:::\n\n\n\n\nWe might be tempted to avoid doing this by removing all the spaces with `str_replace_all`. However, when doing such an operation we need to make sure that it does not have unintended effects. In our reported heights examples, this will be a problem because some entries are of the form `x y` with space separating the feet from the inches. If we remove all spaces, we will incorrectly turn `x y` into `xy` which implies that a `6 1` would become `61` inches instead of `73` inches.\n\n\nThe second large type of problematic entries were of the form `x.y`, `x,y` and `x y`. We want to change all these to our common format `x'y`. But we can't just do a search and replace because we would change values such as `70.5` into `70'5`.\nOur strategy will therefore be to search for a very specific pattern that assures us feet and inches are being provided and then, for those that match, replace appropriately.\n\n### Search and replace using groups\n\nAnother powerful aspect of groups is that you can refer to the extracted values in a regex when searching and replacing.\n\nThe regex special character for the `i`-th group is `\\\\i`. So `\\\\1` is the value extracted from the first group, `\\\\2` the value from the second and so on. As a simple example, note that the following code will replace a comma with period, but only if it is between two digits:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern_with_groups <-  \"^([4-7]),(\\\\d*)$\"\nyes <- c(\"5,9\", \"5,11\", \"6,\", \"6,1\")\nno <- c(\"5'9\", \",\", \"2,8\", \"6.1.1\")\ns <- c(yes, no)\nstr_replace(s, pattern_with_groups, \"\\\\1'\\\\2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5'9\"   \"5'11\"  \"6'\"    \"6'1\"   \"5'9\"   \",\"     \"2,8\"   \"6.1.1\"\n```\n\n\n:::\n:::\n\n\n\n\nWe can use this to convert cases in our reported heights.\n\nWe are now ready to define a pattern that helps us convert all the `x.y`, `x,y` and `x y` to our preferred format. We need to adapt `pattern_with_groups` to be a bit more flexible and capture all the cases.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern_with_groups <-\"^([4-7])\\\\s*[,\\\\.\\\\s+]\\\\s*(\\\\d*)$\"\n```\n:::\n\n\n\n\nLet's break this one down:\n\n  - `^` = start of the string\n  - `[4-7]` = one digit, either 4, 5, 6, or 7\n  - `\\\\s*` = none or more white space\n  - `[,\\\\.\\\\s+]` = feet symbol is either `,`, `.` or at least one space\n  - `\\\\s*` = none or more white space\n  - `\\\\d*` = none or more digits\n  - `$` = end of the string\n\nWe can see that it appears to be working:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_subset(problems, pattern_with_groups) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5.3\"  \"5.25\" \"5.5\"  \"6.5\"  \"5.8\"  \"5.6\" \n```\n\n\n:::\n:::\n\n\n\n\nand will be able to perform the search and replace:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_subset(problems, pattern_with_groups) %>%\n  str_replace(pattern_with_groups, \"\\\\1'\\\\2\") %>% head\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5'3\"  \"5'25\" \"5'5\"  \"6'5\"  \"5'8\"  \"5'6\" \n```\n\n\n:::\n:::\n\n\n\n\nAgain, we will deal with the inches-larger-than-twelve challenge later.\n\n## Testing and improving\n\nDeveloping the right regex on the first try is often difficult. Trial and error is a common approach to finding the regex pattern that satisfies all desired conditions. In the previous sections, we have developed a powerful string processing technique that can help us catch many of the problematic entries. Here we will test our approach, search for further problems, and tweak our approach for possible improvements. Let's write a function that captures all the entries that can't be converted into numbers remembering that some are in centimeters (we will deal with those later):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnot_inches_or_cm <- function(x, smallest = 50, tallest = 84){\n  inches <- suppressWarnings(as.numeric(x))\n  ind <- !is.na(inches) &\n    ((inches >= smallest & inches <= tallest) |\n       (inches/2.54 >= smallest & inches/2.54 <= tallest))\n  !ind\n}\n\nproblems <- reported_heights %>%\n  dplyr::filter(not_inches_or_cm(height)) %>%\n  pull(height)\nlength(problems)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 200\n```\n\n\n:::\n:::\n\n\n\n\nLet's see what proportion of these fit our pattern after the processing steps we developed above:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconverted <- problems %>%\n  str_replace(\"feet|foot|ft\", \"'\") %>% # convert feet symbols to '\n  str_replace(\"inches|in|''|\\\"\", \"\") %>%  # remove inches symbols\n  str_replace(\"^([4-7])\\\\s*[,\\\\.\\\\s+]\\\\s*(\\\\d*)$\", \"\\\\1'\\\\2\")# change format\n\npattern <- \"^[4-7]\\\\s*'\\\\s*\\\\d{1,2}$\"\nindex <- str_detect(converted, pattern)\nmean(index)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.615\n```\n\n\n:::\n:::\n\n\n\n\nNote how we leveraged the pipe, one of the advantages of using __stringr__. This last piece of code shows that we have matched well over half of the strings. Let's examine the remaining cases:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconverted[!index]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"6\"             \"165cm\"         \"511\"           \"6\"            \n [5] \"2\"             \">9000\"         \"5 ' and 8.11 \" \"11111\"        \n [9] \"6\"             \"103.2\"         \"19\"            \"5\"            \n[13] \"300\"           \"6'\"            \"6\"             \"Five ' eight \"\n[17] \"7\"             \"214\"           \"6\"             \"0.7\"          \n[21] \"6\"             \"2'33\"          \"612\"           \"1,70\"         \n[25] \"87\"            \"5'7.5\"         \"5'7.5\"         \"111\"          \n[29] \"5' 7.78\"       \"12\"            \"6\"             \"yyy\"          \n[33] \"89\"            \"34\"            \"25\"            \"6\"            \n[37] \"6\"             \"22\"            \"684\"           \"6\"            \n[41] \"1\"             \"1\"             \"6*12\"          \"87\"           \n[45] \"6\"             \"1.6\"           \"120\"           \"120\"          \n[49] \"23\"            \"1.7\"           \"6\"             \"5\"            \n[53] \"69\"            \"5' 9 \"         \"5 ' 9 \"        \"6\"            \n[57] \"6\"             \"86\"            \"708,661\"       \"5 ' 6 \"       \n[61] \"6\"             \"649,606\"       \"10000\"         \"1\"            \n[65] \"728,346\"       \"0\"             \"6\"             \"6\"            \n[69] \"6\"             \"100\"           \"88\"            \"6\"            \n[73] \"170 cm\"        \"7,283,465\"     \"5\"             \"5\"            \n[77] \"34\"           \n```\n\n\n:::\n:::\n\n\n\n\nFour clear patterns arise:\n\n1. Many students measuring exactly 5 or 6 feet did not enter any inches, for example `6'`, and our pattern requires that inches be included.\n2. Some students measuring exactly 5 or 6 feet entered just that number.\n3. Some of the inches were entered with decimal points. For example `5'7.5''`. Our pattern only looks for two digits.\n4. Some entries have spaces at the end, for example `5 ' 9 `.\n\nAlthough not as common, we also see the following problems:\n\n5. Some entries are in meters and some of these use European decimals: `1.6`, `1,70`.\n6. Two students added `cm`.\n7. A student spelled out the numbers: `Five foot eight inches`.\n\nIt is not necessarily clear that it is worth writing code to handle these last three cases since they might be rare enough. However, some of them provide us with an opportunity to learn a few more regex techniques, so we will build a fix.\n\nFor case 1, if we add a `'0` after the first digit, for example, convert all `6` to `6'0`, then our previously defined pattern will match. This can be done using groups:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- c(\"5\", \"6\", \"5\")\nno <- c(\"5'\", \"5''\", \"5'4\")\ns <- c(yes, no)\nstr_replace(s, \"^([4-7])$\", \"\\\\1'0\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5'0\" \"6'0\" \"5'0\" \"5'\"  \"5''\" \"5'4\"\n```\n\n\n:::\n:::\n\n\n\n\nThe pattern says it has to start (`^`) with a digit between 4 and 7 and end there (`$`). The parenthesis defines the group that we pass as `\\\\1` to generate the replacement regex string.\n\nWe can adapt this code slightly to handle the case 2 as well, which covers the entry `5'`. Note `5'` is left untouched. This is because the extra `'` makes the pattern not match since we have to end with a 5 or 6. We want to permit the 5 or 6 to be followed by 0 or 1 feet sign. So we can simply add `'{0,1}` after the `'` to do this. However, we can use the none or once special character `?`. As we saw above, this is different from `*` which is none or more. We now see that the fourth case is also converted:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_replace(s, \"^([56])'?$\", \"\\\\1'0\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5'0\" \"6'0\" \"5'0\" \"5'0\" \"5''\" \"5'4\"\n```\n\n\n:::\n:::\n\n\n\n\nHere we only permit 5 and 6, but not 4 and 7. This is because 5 and 6 feet tall is quite common, so we assume those that typed 5 or 6 really meant `60` or `72` inches. However, `4` and `7` feet tall are so rare that, although we accept `84` as a valid entry, we assume `7` was entered in error.\n\nWe can use quantifiers to deal with **case 3**. These entries are not matched because the inches include decimals and our pattern does not permit this. We need to allow the second group to include decimals not just digits. This means we must permit zero or one period `.` then zero or more digits. So we will be using both `?` and `*`.\nAlso remember that, for this particular case, the period needs to be escaped since it is a special character (it means any character except line break). Here is a simple example of how we can use `*`.\n\nSo we can adapt our pattern, currently `^[4-7]\\\\s*'\\\\s*\\\\d{1,2}$` to permit a decimal at the end:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^[4-7]\\\\s*'\\\\s*(\\\\d+\\\\.?\\\\d*)$\"\n```\n:::\n\n\n\n\n\nCase 4, meters using commas, we can approach similarly to how we converted the `x.y` to `x'y`. A difference is that we require that the first digit be 1 or 2:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyes <- c(\"1,7\", \"1, 8\", \"2, \" )\nno <- c(\"5,8\", \"5,3,2\", \"1.7\")\ns <- c(yes, no)\nstr_replace(s, \"^([12])\\\\s*,\\\\s*(\\\\d*)$\", \"\\\\1\\\\.\\\\2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"1.7\"   \"1.8\"   \"2.\"    \"5,8\"   \"5,3,2\" \"1.7\"  \n```\n\n\n:::\n:::\n\n\n\n\nWe will later check if the entries are meters using their numeric values. We will come back to the case study after introducing two widely used functions in string processing that will come in handy when developing our final solution for the self-reported heights.\n\n\n## Trimming\n\nIn general, spaces at the start or end of the string are uninformative.\nThese can be particularly deceptive because sometimes they can be hard to see:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- \"Hi \"\ncat(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nHi \n```\n\n\n:::\n\n```{.r .cell-code}\nidentical(s, \"Hi\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\n\nThis is a general enough problem that there is a function dedicated to removing them:\n `str_trim`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_trim(\"5 ' 9 \")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5 ' 9\"\n```\n\n\n:::\n:::\n\n\n\n\n\n## Changing lettercase\n\nNotice that regex is case sensitive. Often we want to match a word regardless of case. One approach to doing this is to first change everything to lower case and then proceeding ignoring case. As an example, note that one of the entries writes out numbers as words `Five foot eight inches`. Although not efficient, we could add 13 extra `str_replace` calls to convert `zero` to `0`, `one` to `1`, and so on. To avoid having to write two separate operations for `Zero` and `zero`, `One` and `one`, etc., we can use the `str_to_lower` function to make all works lower case first:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- c(\"Five feet eight inches\")\nstr_to_lower(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"five feet eight inches\"\n```\n\n\n:::\n:::\n\n\n\n\nOther related functions are `str_to_upper` and `str_to_title`. These are especially useful when you're trying to merge two datasets -- you'll often see state names in various capitalization forms. \n\nWe are now ready to define a procedure that converts all the problematic cases to inches.\n\n## Case study 2: self-reported heights (continued)\n\nWe now put all of what we have learned together into a function that takes a string vector and tries to convert as many strings as possible to one format. We write a function that puts together what we have done above.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconvert_format <- function(s){\n  s %>%\n    str_replace(\"feet|foot|ft\", \"'\") %>%\n    str_replace_all(\"inches|in|''|\\\"|cm|and\", \"\") %>%\n    str_replace(\"^([4-7])\\\\s*[,\\\\.\\\\s+]\\\\s*(\\\\d*)$\", \"\\\\1'\\\\2\") %>%\n    str_replace(\"^([56])'?$\", \"\\\\1'0\") %>%\n    str_replace(\"^([12])\\\\s*,\\\\s*(\\\\d*)$\", \"\\\\1\\\\.\\\\2\") %>%\n    str_trim()\n}\n```\n:::\n\n\n\n\nWe can also write a function that converts words to numbers:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(english)\nwords_to_numbers <- function(s){\n  s <- str_to_lower(s)\n  for(i in 0:11)\n    s <- str_replace_all(s, words(i), as.character(i))\n  s\n}\n```\n:::\n\n\n\n\nNote that we can perform the above operation more efficiently with the function `recode`.\nNow we can see which problematic entries remain:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconverted <- problems %>% words_to_numbers() %>% convert_format()\nremaining_problems <- converted[not_inches_or_cm(converted)]\npattern <- \"^[4-7]\\\\s*'\\\\s*\\\\d+\\\\.?\\\\d*$\"\nindex <- str_detect(remaining_problems, pattern)\nremaining_problems[!index]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"511\"       \"2\"         \">9000\"     \"11111\"     \"103.2\"     \"19\"       \n [7] \"300\"       \"7\"         \"214\"       \"0.7\"       \"2'33\"      \"612\"      \n[13] \"1.70\"      \"87\"        \"111\"       \"12\"        \"yyy\"       \"89\"       \n[19] \"34\"        \"25\"        \"22\"        \"684\"       \"1\"         \"1\"        \n[25] \"6*12\"      \"87\"        \"1.6\"       \"120\"       \"120\"       \"23\"       \n[31] \"1.7\"       \"86\"        \"708,661\"   \"649,606\"   \"10000\"     \"1\"        \n[37] \"728,346\"   \"0\"         \"100\"       \"88\"        \"7,283,465\" \"34\"       \n```\n\n\n:::\n:::\n\n\n\n\napart from the cases reported as meters, which we will fix below, they all seem to be cases that are impossible to fix.\n\n### The `extract` function\n\nThe `extract` function is a useful __tidyverse__ function for string processing that we will use in our final solution, so we introduce it here. In a previous section, we constructed a regex that lets us identify which elements of a character vector match the feet and inches pattern. However, we want to do more. We want to extract and save the feet and number values so that we can convert them to inches when appropriate.\n\nIf we have a simpler case like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- c(\"5'10\", \"6'1\")\ntab <- data.frame(x = s)\n```\n:::\n\n\n\n\nIn an earlier Content section we learned about the `separate` function, which can be used to achieve our current goal:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab %>% separate(x, c(\"feet\", \"inches\"), sep = \"'\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  feet inches\n1    5     10\n2    6      1\n```\n\n\n:::\n:::\n\n\n\n\nThe `extract` function from the __tidyr__ package lets us use regex groups to extract the desired values. Here is the equivalent to the code above using `separate` but using `extract`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyr)\ntab %>% tidyr::extract(x, c(\"feet\", \"inches\"), regex = \"(\\\\d)'(\\\\d{1,2})\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  feet inches\n1    5     10\n2    6      1\n```\n\n\n:::\n:::\n\n\n\n\nSo why do we even need the new function `extract`? We have seen how small changes can throw off exact pattern matching. Groups in regex give us more flexibility. For example, if we define:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- c(\"5'10\", \"6'1\\\"\",\"5'8inches\")\ntab <- data.frame(x = s)\n```\n:::\n\n\n\n\nand we only want the numbers, `separate` fails:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab %>% separate(x, c(\"feet\",\"inches\"), sep = \"'\", fill = \"right\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  feet  inches\n1    5      10\n2    6      1\"\n3    5 8inches\n```\n\n\n:::\n:::\n\n\n\n\nHowever, we can use `extract`. The regex here is a bit more complicated since we have to permit `'` with spaces and `feet`. We also do not want the `\"` included in the value, so we do not include that in the group:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab %>% tidyr::extract(x, c(\"feet\", \"inches\"), regex = \"(\\\\d)'(\\\\d{1,2})\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  feet inches\n1    5     10\n2    6      1\n3    5      8\n```\n\n\n:::\n:::\n\n\n\n\n\n### Putting it all together\n\nWe are now ready to put it all together and wrangle our reported heights data to try to recover as many heights as possible. The code is complex, but we will break it down into parts.\n\nWe start by cleaning up the `height` column so that the heights are closer to a feet'inches format. We added an original heights column so we can compare before and after.\n\nNow we are ready to wrangle our reported heights dataset:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npattern <- \"^([4-7])\\\\s*'\\\\s*(\\\\d+\\\\.?\\\\d*)$\"\n\nsmallest <- 50\ntallest <- 84\nnew_heights <- reported_heights %>%\n  dplyr::mutate(original = height,\n         height = words_to_numbers(height) %>% convert_format()) %>%\n  tidyr::extract(height, c(\"feet\", \"inches\"), regex = pattern, remove = FALSE) %>%\n  dplyr::mutate_at(c(\"height\", \"feet\", \"inches\"), as.numeric) %>%\n  dplyr::mutate(guess = 12 * feet + inches) %>%\n  dplyr::mutate(height = case_when(\n    is.na(height) ~ as.numeric(NA),\n    between(height, smallest, tallest) ~ height,  #inches\n    between(height/2.54, smallest, tallest) ~ height/2.54, #cm\n    between(height*100/2.54, smallest, tallest) ~ height*100/2.54, #meters\n    TRUE ~ as.numeric(NA))) %>%\n  dplyr::mutate(height = ifelse(is.na(height) &\n                           inches < 12 & between(guess, smallest, tallest),\n                         guess, height)) %>%\n  dplyr::select(-guess)\n```\n:::\n\n\n\n\nWe can check all the entries we converted by typing:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_heights %>%\n  dplyr::filter(not_inches(original)) %>%\n  dplyr::select(original, height) %>%\n  arrange(height) %>%\n  View()\n```\n:::\n\n\n\n\n\nA final observation is that if we look at the shortest students in our course:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_heights %>% arrange(height) %>% head(n=7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           time_stamp    sex height feet inches original\n1 2017-07-04 01:30:25   Male  50.00   NA     NA       50\n2 2017-09-07 10:40:35   Male  50.00   NA     NA       50\n3 2014-09-02 15:18:30 Female  51.00   NA     NA       51\n4 2016-06-05 14:07:20 Female  52.00   NA     NA       52\n5 2016-06-05 14:07:38 Female  52.00   NA     NA       52\n6 2014-09-23 03:39:56 Female  53.00   NA     NA       53\n7 2015-01-07 08:57:29   Male  53.77   NA     NA    53.77\n```\n\n\n:::\n:::\n\n\n\n\nWe see heights of 53, 54, and 55. In the originals, we also have 51 and 52. These short heights are rare and it is likely that the students actually meant `5'1`, `5'2`, `5'3`, `5'4`, and `5'5`. Because we are not completely sure, we will leave them as reported. The object `new_heights` contains our final solution for this case study.\n\n## String splitting\n\nAnother very common data wrangling operation is string splitting. To illustrate how this comes up, we start with an illustrative example. Suppose we did not have the function `read_csv` or `read.csv` available to us. We instead have to read a csv file using the base R function `readLines` like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilename <- system.file(\"extdata/murders.csv\", package = \"dslabs\")\nlines <- readLines(filename)\n```\n:::\n\n\n\n\nThis function reads-in the data line-by-line to create a vector of strings. In this case, one string for each row in the spreadsheet. The first six lines are:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlines %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"state,abb,region,population,total\" \"Alabama,AL,South,4779736,135\"     \n[3] \"Alaska,AK,West,710231,19\"          \"Arizona,AZ,West,6392017,232\"      \n[5] \"Arkansas,AR,South,2915918,93\"      \"California,CA,West,37253956,1257\" \n```\n\n\n:::\n:::\n\n\n\n\nWe want to extract the values that are separated by a comma for each string in the vector. The command `str_split` does exactly this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- str_split(lines, \",\")\nx %>% head(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"state\"      \"abb\"        \"region\"     \"population\" \"total\"     \n\n[[2]]\n[1] \"Alabama\" \"AL\"      \"South\"   \"4779736\" \"135\"    \n```\n\n\n:::\n:::\n\n\n\n\nNote that the first entry has the column names, so we can separate that out:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncol_names <- x[[1]]\nx <- x[-1]\n```\n:::\n\n\n\n\nTo convert our list into a data frame, we can use a shortcut provided by the `map` functions in the __purrr__ package. The map function applies the same function to each element in a list. So if we want to extract the first entry of each element in `x`, we can write:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nmap(x, function(y) y[1]) %>% head(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"Alabama\"\n\n[[2]]\n[1] \"Alaska\"\n```\n\n\n:::\n:::\n\n\n\n\nHowever, because this is such a common task, __purrr__ provides a shortcut. If the second argument receives an integer instead of a function, it assumes we want that entry. So the code above can be written more efficiently like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmap(x, 1)\n```\n:::\n\n\n\n\nTo force `map` to return a character vector instead of a list, we can use `map_chr`. Similarly, `map_int` returns integers. So to create our data frame, we can use:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- tibble(map_chr(x, 1),\n              map_chr(x, 2),\n              map_chr(x, 3),\n              map_chr(x, 4),\n              map_chr(x, 5)) %>%\n  mutate_all(parse_guess) %>%\n  setNames(col_names)\ndat %>% head\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  state      abb   region population total\n  <chr>      <chr> <chr>       <dbl> <dbl>\n1 Alabama    AL    South     4779736   135\n2 Alaska     AK    West       710231    19\n3 Arizona    AZ    West      6392017   232\n4 Arkansas   AR    South     2915918    93\n5 California CA    West     37253956  1257\n6 Colorado   CO    West      5029196    65\n```\n\n\n:::\n:::\n\n\n\n\nIf you learn more about the __purrr__ package, you will learn that you perform the above with the following, more efficient, code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- x %>%\n  transpose() %>%\n  map( ~ parse_guess(unlist(.))) %>%\n  setNames(col_names) %>%\n  as_tibble()\n```\n:::\n\n\n\n\n\nIt turns out that we can avoid all the work shown above after the call to `str_split`. Specifically, if we know that the data we are extracting can be represented as a table, we can use the argument `simplify=TRUE` and `str_split` returns a matrix instead of a list:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- str_split(lines, \",\", simplify = TRUE)\ncol_names <- x[1,]\nx <- x[-1,]\ncolnames(x) <- col_names\nx %>% as_tibble() %>%\n  mutate_all(parse_guess) %>%\n  head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n  state      abb   region population total\n  <chr>      <chr> <chr>       <dbl> <dbl>\n1 Alabama    AL    South     4779736   135\n2 Alaska     AK    West       710231    19\n3 Arizona    AZ    West      6392017   232\n4 Arkansas   AR    South     2915918    93\n5 California CA    West     37253956  1257\n```\n\n\n:::\n:::\n\n\n\n\n## Case study 3: extracting tables from a PDF\n\nOne of the datasets provided in __dslabs__ shows scientific funding rates by gender in the Netherlands:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dslabs)\ndata(\"research_funding_rates\")\nresearch_funding_rates %>%\n  dplyr::select(\"discipline\", \"success_rates_men\", \"success_rates_women\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           discipline success_rates_men success_rates_women\n1   Chemical sciences              26.5                25.6\n2   Physical sciences              19.3                23.1\n3             Physics              26.9                22.2\n4          Humanities              14.3                19.3\n5  Technical sciences              15.9                21.0\n6   Interdisciplinary              11.4                21.8\n7 Earth/life sciences              24.4                14.3\n8     Social sciences              15.3                11.5\n9    Medical sciences              18.8                11.2\n```\n\n\n:::\n:::\n\n\n\n\n\nThe data comes from a paper published in the Proceedings of the National Academy of Science (PNAS)^[http://www.pnas.org/content/112/40/12349.abstract], a widely read scientific journal. However, the data is not provided in a spreadsheet; it is in a table in a PDF document. Here is a screenshot of the table:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/pnas-table-s1.png){width=531}\n:::\n:::\n\n\n\n\n(Source: Romy van der Lee and Naomi Ellemers, PNAS 2015 112 (40) 12349-12353^[http://www.pnas.org/content/112/40/12349].)\n\nWe could extract the numbers by hand, but this could lead to human error. Instead, we can try to wrangle the data using R. We start by downloading the pdf document, then importing into R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"pdftools\")\ntemp_file <- tempfile()\nurl <- paste0(\"https://www.pnas.org/content/suppl/2015/09/16/\",\n              \"1510159112.DCSupplemental/pnas.201510159SI.pdf\")\ndownload.file(url, temp_file)\ntxt <- pdf_text(temp_file)\nfile.remove(temp_file)\n```\n:::\n\n\n\n\nIf we examine the object text, we notice that it is a character vector with an entry for each page. So we keep the page we want:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_data_research_funding_rates <- txt[2]\n```\n:::\n\n\n\n\nThe steps above can actually be skipped  because we include this raw data in the __dslabs__ package as well:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"raw_data_research_funding_rates\")\n```\n:::\n\n\n\n\nExamining the object `raw_data_research_funding_rates`\nwe see that it is a long string and each line on the page, including the table rows, are separated by the symbol for newline: `\\n`. We therefore can create a list with the lines of the text as elements as follows:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- str_split(raw_data_research_funding_rates, \"\\n\")\n```\n:::\n\n\n\n\nBecause we start off with just one element in the string, we end up with a list with just one entry.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- tab[[1]]\n```\n:::\n\n\n\n\nBy examining `tab` we see that the information for the column names is the third and fourth entries:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_names_1 <- tab[3]\nthe_names_2 <- tab[4]\n```\n:::\n\n\n\n\nThe first of these rows looks like this:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n                                                      Applications, n           \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Awards, n                      Success rates, %\n```\n\n\n:::\n:::\n\n\n\n\nWe want to create one vector with one name for each column. Using some of the functions we have just learned, we do this. Let's start with `the_names_1`, shown above. We want to remove the leading space and anything following the comma. We use regex for the latter. Then we can obtain the elements by splitting strings separated by space.  We want to split only when there are 2 or more spaces to avoid splitting `Success rates`. So we use the regex `\\\\s{2,}`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_names_1 <- the_names_1 %>%\n  str_trim() %>%\n  str_replace_all(\",\\\\s.\", \"\") %>%\n  str_split(\"\\\\s{2,}\", simplify = TRUE)\nthe_names_1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]           [,2]     [,3]           \n[1,] \"Applications\" \"Awards\" \"Success rates\"\n```\n\n\n:::\n:::\n\n\n\n\n\nNow we will look at `the_names_2`:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n                        Discipline              Total     Men      Women        \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Total    Men       Women          Total    Men      Women\n```\n\n\n:::\n:::\n\n\n\n\nHere we want to trim the leading space and then split by space as we did for the first line:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_names_2 <- the_names_2 %>%\n  str_trim() %>%\n  str_split(\"\\\\s+\", simplify = TRUE)\nthe_names_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]         [,2]    [,3]  [,4]    [,5]    [,6]  [,7]    [,8]    [,9] \n[1,] \"Discipline\" \"Total\" \"Men\" \"Women\" \"Total\" \"Men\" \"Women\" \"Total\" \"Men\"\n     [,10]  \n[1,] \"Women\"\n```\n\n\n:::\n:::\n\n\n\n\nWe can then join these to generate one name for each column:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmp_names <- str_c(rep(the_names_1, each = 3), the_names_2[-1], sep = \"_\")\nthe_names <- c(the_names_2[1], tmp_names) %>%\n  str_to_lower() %>%\n  str_replace_all(\"\\\\s\", \"_\")\nthe_names\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"discipline\"          \"applications_total\"  \"applications_men\"   \n [4] \"applications_women\"  \"awards_total\"        \"awards_men\"         \n [7] \"awards_women\"        \"success_rates_total\" \"success_rates_men\"  \n[10] \"success_rates_women\"\n```\n\n\n:::\n:::\n\n\n\n\nNow we are ready to get the actual data. By examining the `tab` object, we notice that the information is in lines 6 through 14. We can use `str_split` again to achieve our goal:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_research_funding_rates <- tab[6:14] %>%\n  str_trim %>%\n  str_split(\"\\\\s{2,}\", simplify = TRUE) %>%\n  data.frame(stringsAsFactors = FALSE) %>%\n  setNames(the_names) %>%\n  mutate_at(-1, parse_number)\nnew_research_funding_rates %>% as_tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 × 10\n  discipline applications_total applications_men applications_women awards_total\n  <chr>                   <dbl>            <dbl>              <dbl>        <dbl>\n1 Chemical …                122               83                 39           32\n2 Physical …                174              135                 39           35\n3 Physics                    76               67                  9           20\n4 Humanities                396              230                166           65\n5 Technical…                251              189                 62           43\n6 Interdisc…                183              105                 78           29\n7 Earth/lif…                282              156                126           56\n8 Social sc…                834              425                409          112\n9 Medical s…                505              245                260           75\n# ℹ 5 more variables: awards_men <dbl>, awards_women <dbl>,\n#   success_rates_total <dbl>, success_rates_men <dbl>,\n#   success_rates_women <dbl>\n```\n\n\n:::\n:::\n\n\n\n\nWe can see that the objects are identical:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidentical(research_funding_rates, new_research_funding_rates)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n## Recoding\n\nAnother common operation involving strings is recoding the names of categorical variables. Let's say you have really long names for your levels and you will be displaying them in plots, you might want to use shorter versions of these names. For example, in character vectors with country names, you might want to change \"United States of America\" to \"USA\" and \"United Kingdom\" to UK, and so on. We can do this with `case_when`, although the __tidyverse__ offers an option that is specifically designed for this task: the `recode` function.\n\nHere is an example that shows how to rename countries with long names:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dslabs)\ndata(\"gapminder\")\n```\n:::\n\n\n\n\nSuppose we want to show life expectancy time series by country for the Caribbean:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder %>%\n  dplyr::filter(region == \"Caribbean\") %>%\n  ggplot(aes(year, life_expectancy, color = country)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](13a_files/figure-html/caribbean-1.png){width=672}\n:::\n:::\n\n\n\n\nThe plot is what we want, but much of the space is wasted to accommodate some of the long country names.\n<!--\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder %>%\n  dplyr::filter(region == \"Caribbean\") %>%\n  dplyr::filter(str_length(country) >= 12) %>%\n  distinct(country)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                         country\n1            Antigua and Barbuda\n2             Dominican Republic\n3 St. Vincent and the Grenadines\n4            Trinidad and Tobago\n```\n\n\n:::\n:::\n\n\n\n-->\nWe have four countries with names longer than 12 characters. These names appear once for each year in the Gapminder dataset. Once we pick nicknames, we need to change them all consistently. The `recode` function can be used to do this:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder %>% dplyr::filter(region==\"Caribbean\") %>%\n  mutate(country = recode(country,\n                          `Antigua and Barbuda` = \"Barbuda\",\n                          `Dominican Republic` = \"DR\",\n                          `St. Vincent and the Grenadines` = \"St. Vincent\",\n                          `Trinidad and Tobago` = \"Trinidad\")) %>%\n  ggplot(aes(year, life_expectancy, color = country)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](13a_files/figure-html/caribbean-with-nicknames-1.png){width=672}\n:::\n:::\n\n\n\n\nThere are other similar functions in other R packages, such as `recode_factor` and `fct_recoder` in the __forcats__ package.\n\n\n::: {.callout-note}\n\n## TRY IT\n\n1. Complete all lessons and exercises in the [https://regexone.com/](https://regexone.com/) online interactive tutorial.\n\n2. In the `extdata` directory of the __dslabs__ package, you will find a PDF file containing daily mortality data for Puerto Rico from Jan 1, 2015 to May 31, 2018. You can find the file like this: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfn <- system.file(\"extdata\", \"RD-Mortality-Report_2015-18-180531.pdf\",\n                  package=\"dslabs\")\n```\n:::\n\n\n\n\nFind and open the file or open it directly from RStudio. On a Mac, you can type:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem2(\"open\", args = fn)\n```\n:::\n\n\n\n\nand on Windows, you can type:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem(\"cmd.exe\", input = paste(\"start\", fn))\n```\n:::\n\n\n\n\nWhich of the following best describes this file:\n\na. It is a table. Extracting the data will be easy.\nb. It is a report written in prose.  Extracting the data will be impossible.\nc. It is a report combining graphs and tables. Extracting the data seems possible.\nd. It shows graphs of the data. Extracting the data will be difficult.\n\n\n3. We are going to create a tidy dataset with each row representing one observation. The variables in this dataset will be year, month, day, and deaths.\nStart by installing and loading the __pdftools__ package:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"pdftools\")\nlibrary(pdftools)\n```\n:::\n\n\n\n\nNow read-in `fn` using the `pdf_text` function and store the results in an object called `txt`. Which of the following best describes what you see in `txt`?\n\na. A table with the mortality data.\nb. A character string of length 12. Each entry represents the text in each page. The mortality data is in there somewhere.\nc. A character string with one entry containing all the information in the PDF file.\nd. An html document.\n\n\n4. Extract the ninth page of the PDF file from the object `txt`, then use the `str_split` from the __stringr__ package so that you have each line in a different entry. Call this string vector `s`. Then look at the result and choose the one that best describes what you see.\n\na. It is an empty string.\nb. I can see the figure shown in page 1.\nc. It is a tidy table.\nd. I can see the table! But there is a bunch of other stuff we need to get rid of.\n\n\n\n5. What kind of object is `s` and how many entries does it have?\n\n\n6. We see that the output is a list with one component. Redefine `s` to be the first entry of the list. What kind of object is `s` and how many entries does it have?\n\n\n7. When inspecting the string we obtained above, we see a common problem: white space before and after the other characters. Trimming is a common first step in string processing. These extra spaces will eventually make splitting the strings hard so we start by removing them. We learned about the command `str_trim` that removes spaces at the start or end of the strings. Use this function to trim `s`.\n\n\n8. We want to extract the numbers from the strings stored in `s`. However, there are many non-numeric characters that will get in the way. We can remove these, but before doing this we want to preserve the string with the column header, which includes the month abbreviation.\nUse the `str_which` function to find the rows with a header. Save these results to `header_index`. Hint: find the first string that matches the pattern `2015` using the `str_which` function.\n\n\n9. Now we are going to define two objects: `month` will store the month and `header` will store the column names. Identify which row contains the header of the table. Save the content of the row into an object called `header`, then use `str_split` to help define the two objects we need. Hints: the separator here is one or more spaces. Also, consider using the `simplify` argument.\n\n\n10. Notice that towards the end of the page you see a _totals_ row followed by rows with other summary statistics. Create an object called `tail_index` with the index of the _totals_ entry.\n\n\n11. Because our PDF page includes graphs with numbers, some of our rows have just one number (from the y-axis of the plot). Use the `str_count` function to create an object `n` with the number of numbers in each each row. Hint: you can write a regex for number like this `\\\\d+`.\n\n\n12. We are now ready to remove entries from rows that we know we don't need. The entry `header_index` and everything before it should be removed. Entries for which `n` is 1 should also be removed, and the entry `tail_index` and everything that comes after it should be removed as well.\n\n\n13. Now we are ready to remove all the non-numeric entries. Do this using regex and the `str_remove_all` function. Hint: remember that in regex, using the upper case version of a special character usually means the opposite. So `\\\\D` means \"not a digit\". Remember you also want to keep spaces.\n\n\n14. To convert the strings into a table, use the `str_split_fixed` function. Convert `s` into a data matrix with just the day and death count data. Hints: note that the separator is one or more spaces. Make the argument `n` a value that limits the number of columns to the values in the 4 columns and the last column captures all the extra stuff. Then keep only the first four columns. \n\n\n15. Now you are almost ready to finish. Add column names to the matrix, including one called `day`. Also, add a column with the month. Call the resulting object `dat`. Finally, make sure the day is an integer not a character. Hint: use only the first five columns.\n\n\n16. Now finish it up by tidying `tab` with the gather function.\n\n\n17. Make a plot of deaths versus day with color to denote year. Exclude 2018 since we do not have data for the entire year.\n\n\n18. Now that we have wrangled this data step-by-step, put it all together in one R chunk, using the pipe as much as possible. Hint: first define the indexes, then write one line of code that does all the string processing.\n\n\n19. Advanced: let's return to the MLB Payroll example from the web scraping section. Use what you have learned in the web scraping and string processing chapters to extract the payroll for the New York Yankees, Boston Red Sox, and Oakland A's and plot them as a function of time.\n\n:::\n\n# Web scraping\n\n**Note: we've literally never made it this far in lecture, so consider this to be \"bonus\" material.**\n\nThe data we need to answer a question is not always in a spreadsheet ready for us to read. For example, the US murders dataset we used in the R Basics chapter originally comes from this Wikipedia page:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- paste0(\"https://en.wikipedia.org/w/index.php?title=\",\n              \"Gun_violence_in_the_United_States_by_state\",\n              \"&direction=prev&oldid=810166167\")\n```\n:::\n\n\n\n\nYou can see the data table when you visit the webpage:\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/murders-data-wiki-page.png){width=1437}\n:::\n:::\n\n\n\n\n\n(Web page courtesy of Wikipedia^[https://en.wikipedia.org/w/index.php?title=Gun_violence_in_the_United_States_by_state&direction=prev&oldid=810166167]. CC-BY-SA-3.0 license^[https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License]. Screenshot of part of the page.)\n\nUnfortunately, there is no link to a data file. To make the data frame that is loaded when we type `data(murders)`, we had to do some _web scraping_.\n\n_Web scraping_, or _web harvesting_, is the term we use to describe the process of extracting data from a website. The reason we can do this is because the information used by a browser to render webpages is received as a text file from a server. The text is code written in hyper text markup language (HTML). Every browser has a way to show the html source code for a page, each one different. On Chrome, you can use Control-U on a PC and command+alt+U on a Mac. You will see something like this:\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/html-code.png){width=1436}\n:::\n:::\n\n\n\n\n## HTML\n\nBecause this code is accessible, we can download the HTML file, import it into R, and then write programs to extract the information we need from the page. However, once we look at HTML code, this might seem like a daunting task. But we will show you some convenient tools to facilitate the process. To get an idea of how it works, here are a few lines of code from the Wikipedia page that provides the US murders data:\n\n```\n<table class=\"wikitable sortable\">\n<tr>\n<th>State</th>\n<th><a href=\"/wiki/List_of_U.S._states_and_territories_by_population\"\ntitle=\"List of U.S. states and territories by population\">Population</a><br />\n<small>(total inhabitants)</small><br />\n<small>(2015)</small> <sup id=\"cite_ref-1\" class=\"reference\">\n<a href=\"#cite_note-1\">[1]</a></sup></th>\n<th>Murders and Nonnegligent\n<p>Manslaughter<br />\n<small>(total deaths)</small><br />\n<small>(2015)</small> <sup id=\"cite_ref-2\" class=\"reference\">\n<a href=\"#cite_note-2\">[2]</a></sup></p>\n</th>\n<th>Murder and Nonnegligent\n<p>Manslaughter Rate<br />\n<small>(per 100,000 inhabitants)</small><br />\n<small>(2015)</small></p>\n</th>\n</tr>\n<tr>\n<td><a href=\"/wiki/Alabama\" title=\"Alabama\">Alabama</a></td>\n<td>4,853,875</td>\n<td>348</td>\n<td>7.2</td>\n</tr>\n<tr>\n<td><a href=\"/wiki/Alaska\" title=\"Alaska\">Alaska</a></td>\n<td>737,709</td>\n<td>59</td>\n<td>8.0</td>\n</tr>\n<tr>\n```\n\nYou can actually see the data, except data values are surrounded by html code such as `<td>`. We can also see a pattern of how it is stored. If you know HTML, you can write programs that leverage knowledge of these patterns to extract what we want. We also take advantage of a language widely used to make webpages look \"pretty\" called Cascading Style Sheets (CSS). \n\nAlthough we provide tools that make it possible to scrape data without knowing HTML, as a data scientist it is quite useful to learn some HTML and CSS. Not only does this improve your scraping skills, but it might come in handy if you are creating a webpage to showcase your work. There are plenty of online courses and tutorials for learning these. Two examples are Codeacademy^[https://www.codecademy.com/learn/learn-html] and W3schools^[https://www.w3schools.com/].\n\n## The rvest package\n\nThe __tidyverse__ provides a web harvesting package called __rvest__. The first step using this package is to import the webpage into R. The package makes this quite simple:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rvest)\nh <- read_html(url)\n```\n:::\n\n\n\n\n\nNote that the entire Murders in the US Wikipedia webpage is now contained in `h`. The class of this object is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(h)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"xml_document\" \"xml_node\"    \n```\n\n\n:::\n:::\n\n\n\n\nThe __rvest__ package is actually more general; it handles XML documents. XML is a general markup language (that's what the ML stands for) that can be used to represent any kind of data. HTML is a specific type of XML specifically developed for representing webpages. Here we focus on HTML documents.\n\nNow, how do we extract the table from the object `h`? If we print `h`, we don't really see much:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_document}\n<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-toc-available\" lang=\"en\" dir=\"ltr\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body class=\"skin--responsive skin-vector skin-vector-search-vue mediawik ...\n```\n\n\n:::\n:::\n\n\n\n\nWe can see all the code that defines the downloaded webpage using the `html_text` function like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml_text(h)\n```\n:::\n\n\n\n\nWe don't show the output here because it includes thousands of characters, but if we look at it, we can see the data we are after are stored in an HTML table: you can see this in this line of the HTML code above `<table class=\"wikitable sortable\">`. The different parts of an HTML document, often defined with a message in between  `<` and `>`  are referred to as _nodes_. The __rvest__ package includes functions to extract nodes of an HTML document: `html_nodes` extracts all nodes of different types and `html_node` extracts the first one. To extract the tables from the html code we use:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- h %>% html_nodes(\"table\")\n```\n:::\n\n\n\n\nNow, instead of the entire webpage, we just have the html code for the tables in the page:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (2)}\n[1] <table class=\"wikitable sortable\"><tbody>\\n<tr>\\n<th>State\\n</th>\\n<th>\\n ...\n[2] <table class=\"nowraplinks hlist mw-collapsible mw-collapsed navbox-inner\" ...\n```\n\n\n:::\n:::\n\n\n\n\nThe table we are interested is the first one:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_node}\n<table class=\"wikitable sortable\">\n[1] <tbody>\\n<tr>\\n<th>State\\n</th>\\n<th>\\n<a href=\"/wiki/List_of_U.S._states ...\n```\n\n\n:::\n:::\n\n\n\n\n\nThis is clearly not a tidy dataset, not even a data frame. In the code above, you can definitely see a pattern and writing code to extract just the data is very doable. In fact, __rvest__ includes a function just for converting HTML tables into data frames:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- tab[[1]] %>% html_table\nclass(tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n\n\n:::\n:::\n\n\n\n\nWe are now much closer to having a usable data table:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab <- tab %>% setNames(c(\"state\", \"population\", \"total\", \"murder_rate\"))\nhead(tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  state      population total murder_rate\n  <chr>      <chr>      <chr>       <dbl>\n1 Alabama    4,853,875  348           7.2\n2 Alaska     737,709    59            8  \n3 Arizona    6,817,565  309           4.5\n4 Arkansas   2,977,853  181           6.1\n5 California 38,993,940 1,861         4.8\n6 Colorado   5,448,819  176           3.2\n```\n\n\n:::\n:::\n\n\n\n\nWe still have some wrangling to do. For example, we need to remove the commas and turn characters into numbers. Before continuing with this, we will learn a more general approach to extracting information from web sites.\n\n\n## CSS selectors\nThe default look of a webpage made with the most basic HTML is quite unattractive. The aesthetically pleasing pages we see today are made using CSS to define the look and style of webpages. The fact that all pages for a company have the same style usually results from their use of the same CSS file to define the style. The general way these CSS files work is by defining how each of the elements of a webpage will look. The title, headings, itemized lists, tables, and links, for example, each receive their own style including font, color, size, and distance from the margin. CSS does this by leveraging patterns used to define these elements, referred to as _selectors_. An example of such a pattern, which we used above, is `table`, but there are many, many more.\n\nIf we want to grab data from a webpage and we happen to know a selector that is unique to the part of the page containing this data, we can use the `html_nodes` function. However, knowing which selector can be quite complicated.\nIn fact, the complexity of webpages has been increasing as they become more sophisticated. For some of the more advanced ones, it seems almost impossible to find the nodes that define a particular piece of data. However, selector gadgets actually make this possible.\n\nSelectorGadget^[http://selectorgadget.com/] is piece of software that allows you to interactively determine what CSS selector you need to extract specific components from the webpage. If you plan on scraping data other than tables from html pages, we highly recommend you install it. A Chrome extension is available which permits you to turn on the gadget and then, as you click through the page, it highlights parts and shows you the selector you need to extract these parts. There are various demos of how to do this including __rvest__ author Hadley Wickham's\nvignette^[https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html] and other tutorials based on the vignette^[https://stat4701.github.io/edav/2015/04/02/rvest_tutorial/] ^[https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/].\n\n## JSON\n\nSharing data on the internet has become more and more common. Unfortunately, providers use different formats, which makes it harder for data scientists to wrangle data into R. Yet there are some standards that are also becoming more common. Currently, a format that is widely being adopted is the JavaScript Object Notation or JSON. Because this format is very general, it is nothing like a spreadsheet. This JSON file looks more like the code you use to define a list. Here is an example of information stored in a JSON format:\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[\n  {\n    \"name\": \"Miguel\",\n    \"student_id\": 1,\n    \"exam_1\": 85,\n    \"exam_2\": 86\n  },\n  {\n    \"name\": \"Sofia\",\n    \"student_id\": 2,\n    \"exam_1\": 94,\n    \"exam_2\": 93\n  },\n  {\n    \"name\": \"Aya\",\n    \"student_id\": 3,\n    \"exam_1\": 87,\n    \"exam_2\": 88\n  },\n  {\n    \"name\": \"Cheng\",\n    \"student_id\": 4,\n    \"exam_1\": 90,\n    \"exam_2\": 91\n  }\n] \n```\n\n\n:::\n:::\n\n\n\n\nThe file above actually represents a data frame. To read it, we can use the function `fromJSON` from the __jsonlite__ package. Note that JSON files are often made available via the internet. Several organizations provide a JSON API or a web service that you can connect directly to and obtain data. Here is an example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(jsonlite)\nres <- fromJSON('http://ergast.com/api/f1/2004/1/results.json')\n\nciti_bike <- fromJSON(\"http://citibikenyc.com/stations/json\")\n```\n:::\n\n\n\n\nThis downloads a list. The first argument tells you when you downloaded it:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nciti_bike$executionTime\n```\n:::\n\n\n\n\nand the second is a data table:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nciti_bike$stationBeanList %>% as_tibble()\n```\n:::\n\n\n\n\n\nYou can learn much more by examining tutorials and help files from the __jsonlite__ package. This package is intended for relatively simple tasks such as converting data into tables. For more flexibility, we recommend `rjson`.\n\n\n",
    "supporting": [
      "13a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}