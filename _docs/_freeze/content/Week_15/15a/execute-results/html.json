{
  "hash": "4434a00edbdd992452aae4e2cf065fc6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Geospatial with R\"\noutput:\n  blogdown::html_page:\n    toc: true\n---\n\n\n\n\n## Required Reading\n\n- This page.\n\n### Guiding Questions\n\n- What are the building blocks of geospatial data?\n- How do we handle uniquely geospatial properties like distance or spatial correlation?\n\n\n# Geospatial in R\n\nWe will need a handful of new packages for our introduction to geospatial analysis in R. The primary package we will interact with is the `sf` package. `sf` stands for \"simple features.\" It has become the standard for geospatial work in R, and relies on the `rgeos` and `rgdal` libraries (which are themselves `R` compilations of the `geos` and `gdal` libraries). Documentation of sf [can be found here](https://r-spatial.github.io/sf/). \n\nWe will also use the `mapview` package, as well as the `tmaptools` package. Plus, we'll use `tigris` to get state boundaries and `tidycensus` to pull down census maps. Install those, and any of the many dependencies that they also install. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(mapview)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(tmaptools)\n```\n:::\n\n\n\n\n\n## Vector vs. Raster\nThere are two ways of storing 2-D mapped spatial data, *raster* and *vector*. A *vector* representation of a 2-D shape is best described as an irregular polygon with points defining vertices. A square plotted in cartesian coordinates is a vector representation. Conversely, a *raster* image is a grid of cells where each cell is defined as \"in\" or \"out\" of the square. Most computer graphics like JPEG and TIFF are raster graphics and each pixel has an assigned color. To make a raster image of a blue square, we'd make a big grid of pixels, and then color some blue based on their location. To make a blue square in vector form, we'd record *just the location of the corners* and add instructions to color inside the polygon formed by those corners blue.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://vector-conversions.com/images/vector_vs_raster.jpg){width=50%}\n:::\n:::\n\n\n\n\n### Vectors are scalable. Rasters are not\nRasters are great for detail, like pixels in a picture, but they do not scale up very well. Vectors are great for things that do need to scale up. They are also smaller and easier to work with when they aren't trying to replicate photo-realistic images.  Vectors can handle curves by recording the properties of the curve (e.g. bezier curves), while rasters have to approximate curves along the grid of cells, so if you want a smooth curve, you need lots of cells.\n\nGeospatial work is almost always done in vectors because (1) it is easier to store data as vectors, and (2) it is easier to manipulate, project, intersect, or connect vector points, lines, and polygons.\n\nWe are going to work entirely with vectors today.\n\n\n# Vectors: points, lines, and polygons\nMost everything we would want to map can be represented as a point, a line, or a polygon. Points could be the location of power plants in the US, or the location of COVID cases, or the location of major intersections. Lines could be the location of train tracks, the shortest distance between someone's house and the nearest restaurants, or a major road. Polygons could be county boundaries, landowner's lot lines, or bodies of water.\n\nWe can start by making some points, then turning them into a polygon. We'll just use arbitrary coordinates for now, but will move into GPS latitude-longitude coordinates shortly. We'll use `st_multipoint` to create our points object. It takes a numeric matrix only.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmyPoints = tribble(~X, ~Y,\n                   0, 0,\n                   0, 4,\n                   1, 4,\n                   1, 1,\n                   .5, 0,\n                   0, 0)\n\nmyPoints = st_multipoint(as.matrix(myPoints))\nplot(myPoints)\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n### Making polygons\nWe've begun making our first spatial object! Now, we can turn it into a polygon under one condition: the polygon has to \"close\" in order for R to know which side is the inside. In `myPoints`, the *last* point is identical to the *first* point, so R will \"close\" it:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_polygon(list(myPoints)), col = 'darkgreen')\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThat's just one polylgon. Let's add another one. When we created the polygon, we put the points object, `myPoints`, into a list. If we have a list of, say, two points objects, then we'll get two polygons:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmyPoints2 = tribble(~X, ~Y,\n                    1,1,\n                    2,1,\n                    2,2,\n                    1,2,\n                    1,1)\n                    \nmyPoints2 = st_multipoint(as.matrix(myPoints2))\n\nmyPolygons = st_polygon(list(myPoints, myPoints2))\nplot(myPolygons, col = 'lightblue')\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\nNow we can see two polygons. Looking at the `str`ucture of the polygons:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(myPolygons)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ : 'XY' num [1:6, 1:2] 0 0 1 1 0.5 0 0 4 4 1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"X\" \"Y\"\n $ : 'XY' num [1:5, 1:2] 1 2 2 1 1 1 1 2 2 1\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"X\" \"Y\"\n - attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n```\n\n\n:::\n:::\n\n\n\n\nNotice that one of the classes is `sfg`. This is a `sf` package-defined spatial object. \n\n### Getting points on a plot\nOne little-known trick in R is super helpful in spatial work. If you `plot(myPolygons)` in your own R-studio console (so it appears in your \"Plots\" pane, not knit into your document), you can use `click(n)` to interactively get $n$ spatial points in the coordinate system of your plot. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmyClicks = click(n = 3)\nmyClicks = rbind(myClicks, myClicks[1,])  # copy the first point to the last point to \"close\"\nmyNewPolygon = st_polygon(list(st_multipoint(myClicks)))\nplot(myPolygons, col = 'lightblue')\nplot(myNewPolygon, col = 'green', add=T)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n### Making lines\n\nWe could also create a line with our points. I'll leave off the one point we added to \"close\" the polygon. Note that the line is colored blue, not the (uncompleted) polygon.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmyLine = st_linestring(myPoints[1:4,])\nplot(myLine, col = 'blue')\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n# Reading spatial data\nWhile it's fun to draw our own shapes (caution: my definition of fun $\\neq$ your definition of fun), we're probably most interested in finding and using existing spatial data. Let's talk briefly about the types of spatial data out there:\n\n- Shapefiles\n  - Shapefiles are not actually single files - they're usually 4-6 files with similar names and different suffixes like .dbf, .shx, etc. This is because the shapefile format kind of pre-dates our current way of thinking of file storage. The most common program for reading or making shapefiles is ESRI's ArcGIS. It is expensive, cumbersome, and some may say bloated. Our goal in this section is to be able to rescue shapefiles from the clutches of ArcGIS and open them in R\n  \n- GEOJSON\n  - JSON is a way of structuring text data (like a .csv) but with the potential for nests in the data (like our `list` object) where each nest has a different data structure. GEOJSON pairs this with **WKT** or Well-Known Text representations of coordinates and takes care of making sure that each observation in the JSON data has a corresponding polygon in WKT coordinates.\n  \n- KML\n  - Bare-bones storage of coordinates and basic data\n  \n- .RDS\n  - Okay, this is just R's native data type for storage, but it's really helpful for storing `sf` objects\n  \n- Comma separated values (.csv)\n  - Just like the CSV's we've been using, but with Latitude and Longitude columns. Only works for points (one point per .csv line), but is very commonly found. We can use `st_as_sf` to tell R which columns are the latitude and longitude.\n\nWe can open and use any one of these filetypes. I will cover Shapefiles and GEOJSON as the latter has become a very popular way of sharing spatial datasets.\n\n### Where to find spatial data\nSpatial data is all around us! Try searching google for a topic + \"spatial shapefile\". One of my favorite sources for spatial data is the DHS [HIFLD Open database](https://hifld-geoplatform.hub.arcgis.com), which has lots of government datasets that are well-organized by category. Click through, choose the \"open\" database, and when you find something you like, click the \"Download\" button. If there is a GEOJSON or KML file available, **right-click** and copy the link address, or click on **full details** and scroll down to *I want to...View API Resources* and copy the GEOJSON link. Then, use that with `st_read()`. On many maps (including this one), the GeoJSON link is shown under the API drop-down. Use GeoJSON over KML as some systems have issues importing the data fields in KML. \n\n### Loading the data\nWe'll use the `sf` package's `st_read` to open spatial data. Here, I'm loading the Natural Gas Processing Plants data from the Energy section of HIFLD. I'm using the **GeoJSON** option, which `st_read()` knows how to handle:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngasplants = st_read('https://services7.arcgis.com/FGr1D95XCGALKXqM/arcgis/rest/services/NaturalGas_ProcessingPlants_US_EIA/FeatureServer/23/query?outFields=*&where=1%3D1&f=geojson') %>%\n  dplyr::select(name = Plant_Name)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://services7.arcgis.com/FGr1D95XCGALKXqM/arcgis/rest/services/NaturalGas_ProcessingPlants_US_EIA/FeatureServer/23/query?outFields=*&where=1%3D1&f=geojson' \n  using driver `GeoJSON'\nSimple feature collection with 478 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -120.4329 ymin: 26.42119 xmax: -78.6591 ymax: 48.87366\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(gasplants)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -111.9598 ymin: 31.29948 xmax: -95.51805 ymax: 48.73838\nGeodetic CRS:  WGS 84\n                           name                   geometry\n1 50 Buttes Processing Facility POINT (-105.7778 43.85235)\n2                    Ajax Plant  POINT (-100.1163 35.5464)\n3                         Alamo POINT (-95.51805 31.29948)\n4             Allison Gas Plant POINT (-100.1451 35.61864)\n5                 Aloe Ventures POINT (-111.9598 48.73838)\n6            Altamont Gas Plant  POINT (-110.329 40.35807)\n```\n\n\n:::\n:::\n\n\n\n\nThe `sf` data type holds both the data (which here is just the name of the plant) *and* the \"geometry\", which are the points. It's tidy data - one row is one observation of one plant, and each row has a set of coordinates telling us where to find the plant.\n\nWe can use ggplot with `geom_sf()` to plot these points. They're just scattered across the country and we don't automatically get a background map, but here are the points \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(gasplants) + geom_sf() + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nWell, we're missing some context here -- we can kind of make out the point of Texas down there, but it's hard to tell anything about where these plants are located. Let's use `tigris` to get a map of the US, then plot it plus the points. Note we use different `data = ` in each of the `geom_sf()` calls:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nUS <- tigris::states(cb = TRUE, progress_bar = FALSE)  # tigris maps\n\nggplot() + geom_sf(data = US, col = 'gray50') +\n  geom_sf(data = gasplants) + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n\nGetting there. The problem now is that the `tigris` data covers all US territories, which are really spread out! Let's drop down to just Michigan. We can use good old `filter` just like with regular data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMI = tigris::states(cb = TRUE) %>% dplyr::filter(STUSPS=='MI')\n\nggplot() + geom_sf(data = MI, col = 'gray50') +\n  geom_sf(data = gasplants) + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\nWell, now we have a different problem. We want to have only the `gasplants` that are `over` the state of Michigan. That requires a **spatial join**. Luckily, our `tidyverse` syntax **works pretty seamlessly on `sf` objects**. First, we have to take care of a little issue with spatial data. The **projection**\n\n### Projections, briefly\n\nThe *projection* for spatial data is the translation from a 3-D object (e.g. the globe) to a 2-D space (a map, or the cartesian x-y coordinates of our screen). This is no simple matter! There are entire PhD programs dedicated to forming and processing projections and datum (which refer to the shape of the globe, which is not actually round). It can all be a nightmare. Worst of all, projections determine the definition of your coordinates, so you may be at -81 latitude, +30 longitude, but in another projection, you might be 1245349m above some reference point, and -2452849m to the left of that point. Projections define the distance along the X and Y axis, the scale of the coordinates, and a lot of other stuff about your 2-D polygons.\n\nLuckily, over the last few years, very smart people have been working on regularizing \"projections\". Now, we really need to know three things:\n\n1. The *projection* of your data's coordinates when you read it in\n2. The *projection* you want your data to be in when you map it\n3. The *projection* of other spatial data you may want to combine.\n\n#### Importing projected data\nGEOJSON, shapefiles, and KML files usually come with embedded projections stored as **EPSG** numbers like '4326' (incidentally, '4326' is the usual projection for GPS coordinates). Thus, the first one is usually already taken care of. If your data doesnt have a PROJ4 or EPSG number but the coordinates are all between -180 and +180, it's likely in EPSG=4326. If none of those, then the data creator should have *metadata* stating the proejction. It might take some googling and some trial and error.\n\nFor mapping, you might need to *transform* your data between projections (or \"reproject\" it, same thing). We use `st_transform` for this. We only need to give `R` the EPSG (Geodetic Parameter Dataset) of the projection you want to end up in. As long as it's already in a known projection, `R` can re-project it. The projection is refered to by the Coordinate Reference System (CRS). `st_crs` will tell us the projection (EPSG number and a lot more) of any spatial object. If they do not match, then `R` will give an error or, worse, plot them on totally different scales - sometimes you end up with points from the US landing in the middle of the Indian Ocean! In fact, look back at our map of gas plants and the US. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nst_crs(gasplants)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n```\n\n\n:::\n\n```{.r .cell-code}\nst_crs(MI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n```\n\n\n:::\n:::\n\n\n\n\n`gasplants` from HIFLD is in EPSG: 4326, the map of MI is in EPSG: 4269. We can use `st_transform` on the `gasplants` data, which will reproject the points (and won't change the data at all). The data won't be any different, and the points won't look too much different\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngasplants = gasplants %>%\n  st_transform(crs=4269)\n\nggplot(gasplants) + geom_sf() + theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\nBut in a bit, when we spatially join, we'll avoid an error.\n\n\n#### Importing unprojected data\nSometimes, we have data only in .csv format, but with X and Y coordinates (e.g. Longitude and Latitude). To import this data, we do the following:\n\n- Read in from .csv, .xls, etc.\n- Determine the CRS of the data (usually 4326 for gps coordinates)\n- Set the spatial coordinates and CRS\n\n\nWe know how to do the first, and the 2nd and 3rd are done in one step. We'll make a data.frame of city names and use the `tmaptools` package's `geocode_OSM` to get the latitudes and longitudes of the city centers. This function uses open-source Open Street Maps instead of the google API (which is used by `ggmap`). This way, we don't need an API key.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nourCities = geocode_OSM(c('Detroit','Lansing','Grand Rapids','Kalamazoo','Traverse City','Marquette')) %>%\n  select(City = query, lat = lat, lon = lon)\n\nhead(ourCities)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           City      lat       lon\n1       Detroit 42.33155 -83.04664\n2       Lansing 42.73383 -84.55463\n3  Grand Rapids 42.96324 -85.66786\n4     Kalamazoo 42.29171 -85.58723\n5 Traverse City 44.76065 -85.61660\n6     Marquette 46.44815 -87.63059\n```\n\n\n:::\n:::\n\n\n\n\nSince these are GPS-type coordinates, we are going to assume the CRS is EPSG=4326. Longitude is the \"x\" axis, and latitude is the \"y\" axis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nourCities.spatial = st_as_sf(ourCities, coords = c('lon','lat'), crs = 4326)\nhead(ourCities.spatial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -87.63059 ymin: 42.29171 xmax: -83.04664 ymax: 46.44815\nGeodetic CRS:  WGS 84\n           City                   geometry\n1       Detroit POINT (-83.04664 42.33155)\n2       Lansing POINT (-84.55463 42.73383)\n3  Grand Rapids POINT (-85.66786 42.96324)\n4     Kalamazoo POINT (-85.58723 42.29171)\n5 Traverse City  POINT (-85.6166 44.76065)\n6     Marquette POINT (-87.63059 46.44815)\n```\n\n\n:::\n:::\n\n\n\n\nNow we have the point geometries! We can map this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = MI, fill = 'gray90') +\n  geom_sf(data = ourCities.spatial, col = 'blue') +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Mis-projected data\n\nLet's see a *bad* example that assumes the wrong projection when importing `ourCities.spatial`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nourCities.spatial.bad = st_as_sf(ourCities, coords = c('lon','lat'), crs = 4000)\nggplot() +\n  geom_sf(data = MI, fill = 'gray90') +\n  geom_sf(data = ourCities.spatial.bad, col = 'blue') +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n**Ope!** That sure doesn't look right. The wrong projection can derail a project. Luckily, most shapefiles we find in the wild have the projection (CRS) attached. Now you know what a bad one looks like. Back to our correctly-projected data.\n\n\n\n## Spatial merges\nCombining spatial data is the strength of geospatial analysis. We have our map of MI, and we have out points. Let's \"merge\" the points to the map, meaning let's connect the elements in our map (the state of MI) to the elements in our points (gas plants). This is a point-to-polygon merge.\n\n### Point-to-polygon merges\nWe'll use `st_join` to produce an inner join, so we keep only those points that are \"in\" (spatially) the state of Michigan. I'm specifying `join = st_intersects` though this is the default. Note that all the points that remain in the merged `MI.gasplants` are in Michigan, and note that all the data columns from `MI` are now in `gasplants`. We'll use a county map of MI here so we will have the *county* data for each county containing a gas plant.\n\n\n\n\n::: {.cell result='hide'}\n\n```{.r .cell-code}\nMI.counties = counties(state = 'MI', cb = TRUE, progress_bar = FALSE)\n\nMI.gasplants = gasplants %>%\n  st_transform(st_crs(MI.counties)) %>%\n  st_join(MI.counties, left = FALSE,\n          join = st_intersects)\n\nhead(MI.gasplants)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -86.32218 ymin: 43.79656 xmax: -84.01813 ymax: 44.69001\nGeodetic CRS:  NAD83\n                       name STATEFP COUNTYFP COUNTYNS       AFFGEOID GEOID\n20           Aztec Manistee      26      101 01622993 0500000US26101 26101\n28             Beaver Creek      26      039 01622962 0500000US26039 26039\n148                Fraser 8      26      017 01622951 0500000US26017 26017\n162    Goose Lake Gas Plant      26      133 01623009 0500000US26133 26133\n212 Kalkaska Gas Processing      26      079 01622982 0500000US26079 26079\n268        Marion Gas Plant      26      133 01623009 0500000US26133 26133\n        NAME        NAMELSAD STUSPS STATE_NAME LSAD      ALAND     AWATER\n20  Manistee Manistee County     MI   Michigan   06 1404616367 1912438858\n28  Crawford Crawford County     MI   Michigan   06 1441108421   17887265\n148      Bay      Bay County     MI   Michigan   06 1145834939  487713370\n162  Osceola  Osceola County     MI   Michigan   06 1466674406   17425113\n212 Kalkaska Kalkaska County     MI   Michigan   06 1449729130   28020186\n268  Osceola  Osceola County     MI   Michigan   06 1466674406   17425113\n                      geometry\n20  POINT (-86.32218 44.26337)\n28      POINT (-84.818 44.559)\n148 POINT (-84.01813 43.79656)\n162   POINT (-85.4091 44.1106)\n212 POINT (-85.19667 44.69001)\n268 POINT (-85.09891 44.08532)\n```\n\n\n:::\n:::\n\n\n\n\n\nNow, we can plot the counties map with the gasplants over it. We can even use `aes(...)` to `fill` the counties:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n  geom_sf(data = MI.counties, aes(fill = NAME), show.legend = F) +  \n  geom_sf(data = MI.gasplants) + \n  theme_minimal()  \n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\nHuh. Most gas plants in Michigan are to the north of here. Interesting.\n\n### Mapview\nSometimes, we want to be able to zoom in and out. `ggplot` is static, so that won't work too well. Thanks to the `leaflet` engine, the `mapview` packages is stellar for exploration of spatial data. You can specify `zcol = Name` if you want to color by the `Name` field. I can't embed this in the website, but you can run this at home. It will appear in the \"Viewer\" pane, not in the \"Plots\" pane. Unlike the static image here, you will be able to zoom and pan.\n\n```\nmapview(MI.gasplants)\n```\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/MIgas.png){width=388}\n:::\n:::\n\n\n\n\nIn an actual mapview window (not this static image here), clicking on the points or polygons will bring up a pop-up of the data for that row. Mapview is very useful for *exploring* your spatial data. It is **not** useful for presenting your data. Please, never use `mapview` as an output from a markdown code chunk. Use it for exploring, then use `geom_sf()` to present your analysis.\n\nWhile Mapview has many features that you will likely find interesting, one of the more useful features is that you can set the display color, which helps for data exploration. \n```\nmapview(MI.counties, zcol = 'NAME')\n```\n\nThis will set each county in Michigan to a different color (using the `viridis` colors). Another very useful feature of `mapview` is that you can layer plots with `+`. Again, I'm including a static image. Using this command in Rstudio will open an interactive map:\n\n```\nmapview(MI.gasplants) + mapview(MI.counties, zcol = 'NAME')\n```\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](../../images/mapview_ex2.png){width=485}\n:::\n:::\n\n\n\n\n\n### Polygon-to-polygon merges\nThe gas plants and state merge, above, was very simple because points are always either within or not within a polygon. Worst that can happen is some of your points are not over any polygon at all (resulting in `NA` values). But what if you're merging polygons to polygons?\n\nFirst, let's load some (overlapping) polygons. We can load up all of our states again (dropping the territories). We'll also use a map of watersheds (which cross state boundaries). This is the HUC-4 map of the Rockies from the [US Geological Survey](https://hub.arcgis.com/datasets/7f8632f3e3114623b4f5c8f97d935dca_1?geometry=-157.095%2C32.305%2C-73.379%2C44.324). The HUC-4 is a definition of a watershed where the area of the HUC-4 is the area drained by a major tributary:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nUS = states(cb=TRUE) %>%\n  dplyr::filter(!STUSPS %in% c('PR','GU','VI','MP','AS','AK','HI'))\n\nHUC4 = st_read('https://opendata.arcgis.com/datasets/7f8632f3e3114623b4f5c8f97d935dca_1.kml') %>%\n  st_transform(st_crs(US)) %>%\n  dplyr::mutate(randomData = rpois(n(), 20))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `USGS_NHD_Hydrologic_Units__HUCs_' from data source \n  `https://opendata.arcgis.com/datasets/7f8632f3e3114623b4f5c8f97d935dca_1.kml' \n  using driver `KML'\nSimple feature collection with 12 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -121.5779 ymin: 31.5082 xmax: -109.7625 ymax: 45.25827\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot() + \n  geom_sf(data = US, col = 'gray50') +\n  geom_sf(data = HUC4, aes(fill = Name), show.legend = FALSE) + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\nThese watersheds clearly overlap state boundaries. So what happens if we merge them? `sf` will create a new obsveration (row) for every HUC-4 / State combination\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoly.merge = HUC4 %>%\n  st_join(US, left = TRUE)\n\nhead(poly.merge)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -115.7061 ymin: 31.5082 xmax: -111.5061 ymax: 39.30285\nGeodetic CRS:  NAD83\n                        Name Description randomData STATEFP  STATENS\n1             Lower Colorado                     15      32 01779793\n1.1           Lower Colorado                     15      06 01779778\n1.2           Lower Colorado                     15      04 01779777\n2   Lower Colorado-Lake Mead                     22      49 01455989\n2.1 Lower Colorado-Lake Mead                     22      32 01779793\n2.2 Lower Colorado-Lake Mead                     22      04 01779777\n       AFFGEOID GEOID STUSPS       NAME LSAD        ALAND      AWATER\n1   0400000US32    32     NV     Nevada   00 284537290201  1839636284\n1.1 0400000US06    06     CA California   00 403671756816 20293573058\n1.2 0400000US04    04     AZ    Arizona   00 294363973043   855871553\n2   0400000US49    49     UT       Utah   00 213355072799  6529973239\n2.1 0400000US32    32     NV     Nevada   00 284537290201  1839636284\n2.2 0400000US04    04     AZ    Arizona   00 294363973043   855871553\n                          geometry\n1   POLYGON ((-114.6233 36.0304...\n1.1 POLYGON ((-114.6233 36.0304...\n1.2 POLYGON ((-114.6233 36.0304...\n2   POLYGON ((-115.0786 39.3005...\n2.1 POLYGON ((-115.0786 39.3005...\n2.2 POLYGON ((-115.0786 39.3005...\n```\n\n\n:::\n:::\n\n\n\n\nNow, every HUC-4 like \"Lower Colorado\" has multiple observations, one for each STUSPS that it touches. When we plot it, though, each of those observations are still attached to the same HUC-4 polygon. Technically, R is plotting the same HUC multiple times (once for each state) on top of each other, so we don't see them. This is the equivalent of merging your data in a way that duplicates observations.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(poly.merge) + geom_sf() + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\n\nWe have another option in our join - we can ask `st_join` to keep just the `largest`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoly.merge.largest = HUC4 %>%\n  st_join(US, left = TRUE, largest = TRUE)\n\nhead(poly.merge.largest)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -121.255 ymin: 31.5082 xmax: -111.5061 ymax: 42.3448\nGeodetic CRS:  NAD83\n                          Name Description randomData STATEFP  STATENS\n1               Lower Colorado                     15      04 01779777\n2     Lower Colorado-Lake Mead                     22      04 01779777\n3    Northern Mojave-Mono Lake                     26      06 01779778\n4 Central Nevada Desert Basins                     24      32 01779793\n5               North Lahontan                     18      06 01779778\n6   Black Rock Desert-Humboldt                     14      32 01779793\n     AFFGEOID GEOID STUSPS       NAME LSAD        ALAND      AWATER\n1 0400000US04    04     AZ    Arizona   00 294363973043   855871553\n2 0400000US04    04     AZ    Arizona   00 294363973043   855871553\n3 0400000US06    06     CA California   00 403671756816 20293573058\n4 0400000US32    32     NV     Nevada   00 284537290201  1839636284\n5 0400000US06    06     CA California   00 403671756816 20293573058\n6 0400000US32    32     NV     Nevada   00 284537290201  1839636284\n                        geometry\n1 POLYGON ((-114.6233 36.0304...\n2 POLYGON ((-115.0786 39.3005...\n3 POLYGON ((-118.7594 38.3208...\n4 POLYGON ((-114.7211 41.2410...\n5 POLYGON ((-120.1835 41.9743...\n6 POLYGON ((-117.9693 42.3430...\n```\n\n\n:::\n:::\n\n\n\nNow, there is only *one* observation per HUC-4, and it corresponds to the state that has the most overlap area-wise. For Lower Colorado, Arizona has the most overlap. There are lots of things besides `st_intersect` we can use to call two things \"joined\". `?st_join` tells you about them. For instance, we can use `join = st_covers` and we will only get a merge when HUC-4 completely covers the state.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHUC4 %>%\n  st_join(US, left = TRUE, join = st_covers) %>%\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -121.255 ymin: 31.5082 xmax: -111.5061 ymax: 42.3448\nGeodetic CRS:  NAD83\n                          Name Description randomData STATEFP STATENS AFFGEOID\n1               Lower Colorado                     15    <NA>    <NA>     <NA>\n2     Lower Colorado-Lake Mead                     22    <NA>    <NA>     <NA>\n3    Northern Mojave-Mono Lake                     26    <NA>    <NA>     <NA>\n4 Central Nevada Desert Basins                     24    <NA>    <NA>     <NA>\n5               North Lahontan                     18    <NA>    <NA>     <NA>\n6   Black Rock Desert-Humboldt                     14    <NA>    <NA>     <NA>\n  GEOID STUSPS NAME LSAD ALAND AWATER                       geometry\n1  <NA>   <NA> <NA> <NA>    NA     NA POLYGON ((-114.6233 36.0304...\n2  <NA>   <NA> <NA> <NA>    NA     NA POLYGON ((-115.0786 39.3005...\n3  <NA>   <NA> <NA> <NA>    NA     NA POLYGON ((-118.7594 38.3208...\n4  <NA>   <NA> <NA> <NA>    NA     NA POLYGON ((-114.7211 41.2410...\n5  <NA>   <NA> <NA> <NA>    NA     NA POLYGON ((-120.1835 41.9743...\n6  <NA>   <NA> <NA> <NA>    NA     NA POLYGON ((-117.9693 42.3430...\n```\n\n\n:::\n:::\n\n\n\n\nNone of the HUC-4's completely cover a state, so we get `NA` for all the state data.\n\nThe other thing we can do is ask `R` to create separate polygons - one for every HUC-4 / state combination. That isn't a merge, but it plays a similar role. Note this uses `st_intersection`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoly.int = HUC4 %>%\n  st_intersection(US) %>%\n  arrange(Name)\n\nhead(poly.int)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 12 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -120.4649 ymin: 35.40541 xmax: -114.1471 ymax: 42.3448\nGeodetic CRS:  NAD83\n                            Name Description randomData STATEFP  STATENS\n6     Black Rock Desert-Humboldt                     14      32 01779793\n6.1   Black Rock Desert-Humboldt                     14      06 01779778\n6.2   Black Rock Desert-Humboldt                     14      41 01155107\n7               Central Lahontan                     16      32 01779793\n7.1             Central Lahontan                     16      06 01779778\n4   Central Nevada Desert Basins                     24      32 01779793\n       AFFGEOID GEOID STUSPS       NAME LSAD        ALAND      AWATER\n6   0400000US32    32     NV     Nevada   00 284537290201  1839636284\n6.1 0400000US06    06     CA California   00 403671756816 20293573058\n6.2 0400000US41    41     OR     Oregon   00 248628414476  6170965739\n7   0400000US32    32     NV     Nevada   00 284537290201  1839636284\n7.1 0400000US06    06     CA California   00 403671756816 20293573058\n4   0400000US32    32     NV     Nevada   00 284537290201  1839636284\n                          geometry\n6   MULTIPOLYGON (((-119.9997 4...\n6.1 MULTIPOLYGON (((-119.9997 4...\n6.2 MULTIPOLYGON (((-118.7203 4...\n7   POLYGON ((-120.0065 39.2721...\n7.1 POLYGON ((-120.0016 39.5794...\n4   POLYGON ((-115.1379 35.4054...\n```\n\n\n:::\n:::\n\n\n\n\nNow, we have a unique polygon for every combination of HUC-4 and State (with the US):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + \n  geom_sf(data = US, fill = 'gray50') +\n  geom_sf(data = poly.int, aes(fill = STUSPS), show.legend = FALSE) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n\nHere, I've set the fill to the state, but you can see that the HUC-4's have boundaries at the state line.\n\n### Summarizing \nOur `summarize` function let us collapse by groups and calculate interseting things like average (over a group or region). The neat part is that *it works on spatial data as well*. Let's look at the data again:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(poly.int %>% \n       dplyr::select(Name, randomData, STUSPS) %>%\n       arrange(STUSPS))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 3 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -120.4649 ymin: 32.2603 xmax: -111.5061 ymax: 41.10578\nGeodetic CRS:  NAD83\n                            Name randomData STUSPS\n1.2               Lower Colorado         15     AZ\n2.2     Lower Colorado-Lake Mead         22     AZ\n6.1   Black Rock Desert-Humboldt         14     CA\n7.1             Central Lahontan         16     CA\n4.1 Central Nevada Desert Basins         24     CA\n1.1               Lower Colorado         15     CA\n                          geometry\n1.2 POLYGON ((-114.8165 32.5069...\n2.2 POLYGON ((-114.7368 36.0159...\n6.1 MULTIPOLYGON (((-119.9997 4...\n7.1 POLYGON ((-120.0016 39.5794...\n4.1 MULTIPOLYGON (((-118.7021 3...\n1.1 POLYGON ((-115.1379 35.4054...\n```\n\n\n:::\n:::\n\n\n\n\nSo AZ has two HUC-4's in it - Lower Colorado and Lower Coloardo - Lake Mead (you can see them above). Summarize on geospatial data works just like regular data - we can `group_by(STUSPS)`, and we can `summarize()` any of the data. I threw some random data into `HUC-4` so we can summarize that. \n\nBut how do we combine data specific to each HUC-4 in AZ? We could:\n\n- Just take the average of all of the `randomData` values within the state.\n\n- Take a weighted average of `randomData` where the *area* is the weight\n\n- Take some other function (min, max, etc.) of `randomData`.\n\nWe can implement any of these using `sf`. Let's do the second since it nests the first. First, we'll add the area of the State x HUC-4 using `st_area`, which gives a `units` object. We can turn that into a numeric:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoly.int.summary = poly.int %>%\n  dplyr::mutate(State.HUC.area = as.numeric(st_area(.))) %>%\n  group_by(STUSPS) %>%\n  dplyr::summarize(mean.randomData = weighted.mean(randomData, w = State.HUC.area))\n\nhead(poly.int.summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -121.5779 ymin: 32.2603 xmax: -111.0436 ymax: 45.25827\nGeodetic CRS:  NAD83\n# A tibble: 6 × 3\n  STUSPS mean.randomData                                                geometry\n  <chr>            <dbl>                                          <GEOMETRY [°]>\n1 AZ                18.9 POLYGON ((-114.7368 36.01591, -114.737 36.01577, -114.…\n2 CA                23.3 POLYGON ((-118.9235 38.25064, -118.9497 38.26894, -118…\n3 ID                17.2 POLYGON ((-117.243 44.39097, -117.2351 44.37385, -117.…\n4 MT                18   MULTIPOLYGON (((-111.3842 44.75446, -111.3846 44.75484…\n5 NV                19.8 POLYGON ((-118.7021 38.09324, -118.6216 38.03439, -118…\n6 OR                20.7 POLYGON ((-116.7012 45.24284, -116.7016 45.24301, -116…\n```\n\n\n:::\n:::\n\n\n\n\n`sf` with the `tidyverse` makes it really easy to apply spatial versions of `summarize` and `mutate`. Very useful.\n\nIf we had wanted to just take the average (ignoring area), we'd just leave out the `w = State.HUC.area` or just used `mean`. If we had wanted to take, say, the minimum, we would use `min(randomData)` instead of `weighted.mean`. We can use whatever function we want in `summarize`, just as we did with non-spatial data.\n\n\n## Cropping vs. merging\nSometimes, we wish to only crop to a region rather than merging. `sf` has the `st_crop` function to do this. Let's crop our `HUC-4` data to just the **bounding box** of the state of Nevada\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHUC4.nv = HUC4 %>%\n  st_crop(US %>% dplyr::filter(STUSPS=='NV'))\n\nggplot(HUC4.nv) + geom_sf(aes(fill = Name), show.legend = F) +\n  geom_sf(data = US %>% dplyr::filter(STUSPS=='NV'),  fill = NA, col = 'gray20', lwd = 3 ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\n\n\nIf we wanted to actually crop to the state of Nevada (`st_crop` only uses the bounding box of Nevada), we'd use `st_intersection` but do the intersection with just the state of Nevada:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHUC4.nv = HUC4 %>%\n  st_intersection(US %>% dplyr::filter(STUSPS=='NV'))\n\nggplot(HUC4.nv) + geom_sf(aes(fill = Name), show.legend = F) +\n  geom_sf(data = US %>% dplyr::filter(STUSPS=='NV'),  fill = NA, col = 'gray20', lwd = 3 ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n\nNote that the data for each HUC-4 remains unchanged. If there were something in that data (like \"population\" or \"area\") that is specific to the entire polygon representing the HUC, then cropping the HUC outside of Nevada may lead to misleading data. The moral of the story is: be careful and thoughtful!\n\n### Bounding boxes\n\nThis introduces a useful concept: the *bounding box*. The bounding box is defined by the closest 4 points that form a box that perfectly encloses the object (even when the object is not a rectangle). The extent of the above plot is the bounding box for Nevada.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNevada.bbox = st_bbox(US %>% dplyr::filter(STUSPS=='NV'))\nNevada.bbox\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      xmin       ymin       xmax       ymax \n-120.00646   35.00186 -114.03965   42.00221 \n```\n\n\n:::\n:::\n\n\n\nThe bounding box can be used to frame a \"window\" in a `ggplot` using `geom_sf()`. That is, sometimes, we want to *plot* just a subsection of a map, but we still want the data to be the whole map. Here's an example using the HOLC Redlining Maps, which were created in the 1930's and were used to segregate US housing up until the 1970's. They are available at the [University of Richmond's *Mapping Inequality* site](https://dsl.richmond.edu/panorama/redlining). We can load Lansing and Detroit using the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlansing = st_read('https://dsl.richmond.edu/panorama/redlining/static/citiesData/MILansing19XX/geojson.json')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `geojson' from data source \n  `https://dsl.richmond.edu/panorama/redlining/static/citiesData/MILansing19XX/geojson.json' \n  using driver `GeoJSON'\nSimple feature collection with 5 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.60737 ymin: 42.67877 xmax: -84.45292 ymax: 42.77022\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\ndetroit = st_read('https://dsl.richmond.edu/panorama/redlining/static/citiesData/MIDetroit1939/geojson.json')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `geojson' from data source \n  `https://dsl.richmond.edu/panorama/redlining/static/citiesData/MIDetroit1939/geojson.json' \n  using driver `GeoJSON'\nSimple feature collection with 239 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -83.40036 ymin: 42.13495 xmax: -82.87287 ymax: 42.56012\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nmi.redlining = bind_rows(lansing, detroit) %>%\n  st_transform(st_crs(MI))\n\nggplot(mi.redlining) +\n  geom_sf(aes(fill = grade, col = grade)) + \n  geom_sf(data = MI, fill = NA, col = 'gray50') +\n  scale_fill_manual(values = c('A' = 'darkgreen', 'B' = 'blue', 'C' = 'yellow', 'D' = 'red'),\n                    aesthetics = c('color','fill')) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can tell that our polygons have plotted, but since we have the whole state of Michigan, they're almost unreadable. We need to set our window over the lower part of the lower peninsula. We'll use `coord_sf` to do this, but first we need to define a window. Since windows are almost always rectangular, we can use the `st_bbox(mi.redlining)`, but we have to pull out the xlim (xmin, xmax) and ylim (ymin, ymax):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mi.redlining) +\n  geom_sf(aes(fill = grade, col = grade)) + \n  geom_sf(data = MI, fill = NA, col = 'gray50') +\n  scale_fill_manual(values = c('A' = 'green', 'B' = 'blue', 'C' = 'yellow', 'D' = 'red'),\n                    aesthetics = c('color','fill')) +\n  theme_minimal() +\n  coord_sf(xlim = st_bbox(mi.redlining)[c(1, 3)],\n           ylim = st_bbox(mi.redlining)[c(2, 4)])\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Distance matrices\nOne of the most common spatial statistics we'd use in data analytics is the *distance* matrix. If we have a set of points and we think that we can explain some data about those points (unemployment, ag production, murders per capita) based on the distance to some explanatory source (gas plants, superfund site, etc.), then we might want to include *distance to gas plants* in our model as a predictor. Frequently, we'll use inverse distance, $\\frac{1}{d}$, so that closer things can have more of an impact. To do this, we need a distance matrix.\n\nLet's combine our `gasplants` and our `ourCities` to get the distance from each of our cities to the nearest gas plant. Maybe we have city-level data on student achievements and we want to see if gas plants lower student achievement. While we would need a lot more information to make this model, we can look at what we have for now.\n\nWe will use `st_distance`, which will generate a special type of object that contains the distance information. `MI.gasplants` has 9 observations, and ourCities has 6, so for each row in `ourCities` we will get 9 distances, one to each gasplant. This forms a *distance matrix* where each row is an object in `ourCities` and each column is an object in `MI.gasplants`. We are going to take only a few `MI.gasplants` so we can easily view the results:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nourCities.spatial = ourCities.spatial %>% \n  st_transform(st_crs(MI.gasplants))\n\nMI.gasplants.small = MI.gasplants[1:4,]\n\nourDistance = st_distance(x = ourCities.spatial, y = MI.gasplants.small)\nourDistance\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnits: [m]\n          [,1]      [,2]     [,3]      [,4]\n[1,] 341143.11 285982.39 181009.4 275255.21\n[2,] 221918.02 204053.49 125901.8 167922.72\n[3,] 153864.33 190110.91 162360.3 129274.21\n[4,] 227166.32 259648.90 210370.0 202766.55\n[5,]  78661.48  67024.32 166385.3  74135.81\n[6,] 263562.31 303561.81 408893.5 312655.34\n```\n\n\n:::\n:::\n\n\n\nWe get a `units` matrix, which has extra properties that allow us to convert the units. The units will be in whatever the CRS of the objects is in - `st_crs(ourCities.spatial)` tells us the units are meters.\n\nWhat if we wanted to find the closest gas plant to each city? That is akin to looking at each row, and finding the column that is the smallest, right? We will use `apply`, and we will note that the order of the columns is the same as the order in `MI.gasplants.small`, so we can use `MI.gasplants.small$name` to tell us the name of the closest gas plant. We will `apply` over each row (`MAR=1`) and use the `which.min` function, which returns the *index* number of the maximum column.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmax.index = apply(ourDistance, MAR = 1, which.min)\n```\n:::\n\n\n\n\nWe can combine this index with the `MI.gasplants.small` object to get the names of the closest gas plant for each of the cities. We'll make a nice, neat tibble with the city name (in the order from ourCities.spatial), the closest gas plant name, and the distance to that plant:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(City = ourCities.spatial$City,\n       Closest.gasplant = MI.gasplants.small$name[max.index],\n       Distance.to.closest = ourDistance[cbind(1:length(max.index), max.index)])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  City          Closest.gasplant     Distance.to.closest\n  <chr>         <chr>                                [m]\n1 Detroit       Fraser 8                         181009.\n2 Lansing       Fraser 8                         125902.\n3 Grand Rapids  Goose Lake Gas Plant             129274.\n4 Kalamazoo     Goose Lake Gas Plant             202767.\n5 Traverse City Beaver Creek                      67024.\n6 Marquette     Aztec Manistee                   263562.\n```\n\n\n:::\n:::\n\n\n\n\nBut wait, what is going on in the last line of code there? Well, recall our distance matrix and `max.index`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nourDistance\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnits: [m]\n          [,1]      [,2]     [,3]      [,4]\n[1,] 341143.11 285982.39 181009.4 275255.21\n[2,] 221918.02 204053.49 125901.8 167922.72\n[3,] 153864.33 190110.91 162360.3 129274.21\n[4,] 227166.32 259648.90 210370.0 202766.55\n[5,]  78661.48  67024.32 166385.3  74135.81\n[6,] 263562.31 303561.81 408893.5 312655.34\n```\n\n\n:::\n\n```{.r .cell-code}\n#\nmax.index\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3 3 4 4 2 1\n```\n\n\n:::\n:::\n\n\n\n\nwe want to select from our distance matrix the 1st row, 3rd column; the 2nd row, 3rd column; 3rd row, 1st column; 4th row, 3rd column; 5th row, 4th column; and 6th row, 4th column. This means the row index and column index are not ranges, but are paired. Using `cbind(1:6, max.index)` makes them paired entries, and we can select specific row x column combinations that way.\n\n### st_nearest_feature\nAs is common in R, there is a function that will get the closest points between to spatial objects. `st_nearest_points` takes two geometries, and returns  the neaarest point in `y` for every point in `x`, which is what we did with the MI gas plants.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nst_nearest_feature(x = ourCities.spatial, y = MI.gasplants.small)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3 3 4 4 2 1\n```\n\n\n:::\n:::\n\n\n\nThis is exactly our `max.index` and can be used on the `y` object, `MI.gasplants.small`, to pull the names, subset, get distances etc.\n\n`st_nearest_feature` also works for points and polygons, or polygons and polygons, where it returns the index of the polygon that contains the nearest point to the features in `x`. Let's find the nearest Great Lake for each of our cities using a [KML shapefile of the Great Lakes from WI DNR](https://hub.arcgis.com/datasets/wi-dnr::great-lakes?geometry=-127.301%2C37.038%2C-43.585%2C48.298) Note that the GeoJSON link is under \"API\" on this site. We run into a complex geometry problem, and add `st_make_valid()` to fix it: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGL = st_read('https://opendata.arcgis.com/datasets/a8bb79fc10e64eee8c3a9db97cc5dc80_4.geojson') %>%\n  st_transform(st_crs(ourCities.spatial)) %>% st_make_valid()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Great_Lakes' from data source \n  `https://opendata.arcgis.com/datasets/a8bb79fc10e64eee8c3a9db97cc5dc80_4.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 15 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -92.10222 ymin: 41.38576 xmax: -75.95819 ymax: 49.00535\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\nclosest.GL.index = st_nearest_feature(x = ourCities.spatial, y = GL)\nourCities %>% dplyr::mutate(Closest.GreatLake = GL$FEAT_NAME[closest.GL.index])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           City      lat       lon Closest.GreatLake\n1       Detroit 42.33155 -83.04664         Lake Erie\n2       Lansing 42.73383 -84.55463        Lake Huron\n3  Grand Rapids 42.96324 -85.66786     Lake Michigan\n4     Kalamazoo 42.29171 -85.58723     Lake Michigan\n5 Traverse City 44.76065 -85.61660     Lake Michigan\n6     Marquette 46.44815 -87.63059     Lake Superior\n```\n\n\n:::\n:::\n\n\n\n\n\n## Other resources\n- Claudia Engel's \"[Using Spatial Data with R](https://cengel.github.io/R-spatial/)\" is a very useful resource. It covers `sf` and an older geospatial library called `sp` that has similar functionality but was not tidyverse-friendly. \n\n- The [Rstudio Spatial Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/master/sf.pdf).\n\n  - There are [lots of useful RStudio cheat sheets, actually.](https://www.rstudio.com/resources/cheatsheets/)\n\n- If you want to remove the Great Lakes from your map, here's how you do it\n\n  - First, retrieve the geojson file of the great lakes. Only WI DNR seems to have a public shapefile of the Great Lakes (an informal complaint has been registered with MI-EGLE, grrrr) which you can download as a [geojson from here](https://data-wi-dnr.opendata.arcgis.com/datasets/great-lakes/explore) -- see the little cloud download button, and select geojson. This one doesn't have a link to take it directly, so download the file to your local drive, keep it with your .RMD file, and load it direction from your local path.\n  \n  - Second, use the code below as an example. You may have a different shapefile you want to clip to the Great Lakes -- put it in place of `MI` below. Note that we use a spatial version of the `difference` function, which gives us \"everything in the first that isn't in the second\". \n  \n```\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tigris)\n\n\nMI = counties(state = 'MI', year = 2019) # your map here\nGreatLakes = st_read('/PUT YOUR LOCAL FILEPATH TO THE GEOJSON HERE.geojson') %>%  # put your local filepath in here\n  st_transform(st_crs(MI)) %>%  # need them to be in the same projection\n  st_make_valid() %>%  # this fixes an issue with the shapefile after projection\n  st_union()  # we will put all the lakes together as we don't care which lake is being used to erase county/district boundaries\n\n\nMIx = st_difference(MI, GreatLakes)  # spatial version of the difference function\n```\n\nor, try the `erase_water()` function from `tigris`. This erases any body of water, no matter how small, so on a whole state, it can take a **long** time. The `area_threshold` argument (0 to 1) tells R how detailed you want the erasure to be. A threshold of .999 will remove Great Lakes and big lakes, but leave most inland lakes and won't take as long.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMI = counties(state = 'MI', progress_bar = FALSE) %>%\nerase_water(area_threshold = .999)\n\nggplot(MI) + geom_sf()\n```\n\n::: {.cell-output-display}\n![](15a_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "15a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}